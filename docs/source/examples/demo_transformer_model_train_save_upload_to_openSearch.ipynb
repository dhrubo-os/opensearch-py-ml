{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fba4c02d",
   "metadata": {},
   "source": [
    "# Demo Notebook for Sentence Transformer Model Training, Saving and Uploading to OpenSearch\n",
    "This notebook provides a walkthrough guidance for users use their synthetic queries to fine tune and train a sentence transformer model. In this notebook, you use opensearch_py_ml to accomplish the following:\n",
    "\n",
    "Step 0: Import packages and set up client\n",
    "\n",
    "Step 1: Read synthetic queries and train/fine-tune model using a hugging face sentence transformer model\n",
    "\n",
    "Step 2: (Optional) Save model\n",
    "\n",
    "Step 3: Upload the model to OpenSearch cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7011727e",
   "metadata": {},
   "source": [
    "## Step 0: Import packages and set up client\n",
    "Install required packages for opensearch_py_ml.sentence_transformer_model\n",
    "Install `opensearchpy` and `opensearch-py-ml` through pypi\n",
    "\n",
    "Please refer https://pytorch.org/ to proper install torch based on your environment setting.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a3e085",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install pandas matplotlib numpy torch accelerate sentence_transformers tqdm transformers opensearch-py opensearch-py-ml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87c021df",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import opensearch_py_ml as oml\n",
    "from opensearchpy import OpenSearch\n",
    "from opensearch_py_ml.ml_models import SentenceTransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "798cac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlcommon to later upload the model to OpenSearch Cluster\n",
    "from opensearch_py_ml.ml_commons import MLCommonClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c85ae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_URL = 'https://localhost:9200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77442abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_os_client(cluster_url = CLUSTER_URL,\n",
    "                  username='admin',\n",
    "                  password='admin'):\n",
    "    '''\n",
    "    Get OpenSearch client\n",
    "    :param cluster_url: cluster URL like https://ml-te-netwo-1s12ba42br23v-ff1736fa7db98ff2.elb.us-west-2.amazonaws.com:443\n",
    "    :return: OpenSearch client\n",
    "    '''\n",
    "    client = OpenSearch(\n",
    "        hosts=[cluster_url],\n",
    "        http_auth=(username, password),\n",
    "        verify_certs=False\n",
    "    )\n",
    "    return client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89e1cb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = get_os_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da9e0de",
   "metadata": {},
   "source": [
    "## Step 1: Read synthetic queries and train/fine-tune model using a hugging face sentence transformer model\n",
    "With a synthetic queries zip file, users can fine tune a sentence transformer model. \n",
    "\n",
    "The `SentenceTransformerModel` class will inititate an object for training, exporting and configuring the model. Plese visit the [SentenceTransformerModel](https://opensearch-project.github.io/opensearch-py-ml/reference/api/sentence_transformer.html#opensearch_py_ml.sentence_transformer_model.SentenceTransformerModel) for API Reference . \n",
    "\n",
    "The `train` function will import synthestic queries, load sentence transformer example and train the model using a hugging face sentence transformer model. Plese visit the [SentenceTransformerModel.train](https://opensearch-project.github.io/opensearch-py-ml/reference/api/sentence_transformer.html#opensearch_py_ml.sentence_transformer_model.SentenceTransformerModel.train) for API Reference . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1a337ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up cache before training to free up spaces\n",
    "import gc, torch\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b37e9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading synthetic query file: /Volumes/workplace/upload_content/model_files/synthetic_queries/synthetic_queries_batch_3.p\n",
      "\n",
      "reading synthetic query file: /Volumes/workplace/upload_content/model_files/synthetic_queries/synthetic_queries_batch_0.p\n",
      "\n",
      "reading synthetic query file: /Volumes/workplace/upload_content/model_files/synthetic_queries/synthetic_queries_batch_1.p\n",
      "\n",
      "reading synthetic query file: /Volumes/workplace/upload_content/model_files/synthetic_queries/synthetic_queries_batch_2.p\n",
      "\n",
      "Loading training examples... \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 243/243 [00:00<00:00, 148986.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated config file: at /Users/dhrubo/.cache/huggingface/accelerate/default_config.yaml\n",
      "\n",
      "[{'compute_environment': 'LOCAL_MACHINE', 'deepspeed_config': {'gradient_accumulation_steps': 1, 'offload_optimizer_device': 'none', 'offload_param_device': 'none', 'zero3_init_flag': False, 'zero_stage': 2}, 'distributed_type': 'DEEPSPEED', 'downcast_bf16': 'no', 'fsdp_config': {}, 'machine_rank': 0, 'main_process_ip': None, 'main_process_port': None, 'main_training_function': 'main', 'mixed_precision': 'no', 'num_machines': 1, 'num_processes': 1, 'use_cpu': False}]\n",
      "generating config file for ml common upload: /Users/dhrubo/.cache/huggingface/accelerate/default_config.yaml\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on MPS.\n",
      "Start training with accelerator...\n",
      "\n",
      "The number of training epoch are 1\n",
      "\n",
      "The total number of steps training epoch are 8\n",
      "\n",
      "Training epoch 0...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:16<00:00,  2.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 17.660495042800903\n",
      "\n",
      "Preparing model to save...\n",
      "\n",
      "Model saved to path: /Volumes/workplace/upload_content/model_files/test2_model.pt\n",
      "\n",
      "model path is:  /Volumes/workplace/upload_content/model_files/test2_model.pt\n",
      "Zip file name without extension:  test2_model\n",
      "tokenizer_json_path:  /Volumes/workplace/upload_content/model_files/tokenizer.json\n",
      "zip file is saved to /Volumes/workplace/upload_content/model_files/test2_model.zip\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initiate SentenceTransformerModel object and run train function\n",
    "# num_processes should be less than the number of gpus on the users' machine, if None, it will auto apply \n",
    "# all the available gpus on the machine \n",
    "custom_model = SentenceTransformerModel(folder_path=\"/Volumes/workplace/upload_content/model_files/\", overwrite = True)\n",
    "training = custom_model.train(read_path = '/Volumes/workplace/upload_content/synthetic_queries.zip',\n",
    "                        output_model_name = 'test2_model.pt',\n",
    "                        zip_file_name= 'test2_model.zip',\n",
    "                        overwrite = False,\n",
    "                        use_accelerate  = True,  \n",
    "                        num_machines = 1,\n",
    "                        num_processes = 1,\n",
    "                        num_epochs = 1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a655a9c",
   "metadata": {},
   "source": [
    "## Step 2: (Optional) Save model\n",
    "If following step 1, the model zip will be auto generated, and the print message will indicate the zip file path as shown above. \n",
    "\n",
    "But if using other pretrained sentence transformer model from Hugging face, users can use `save_as_pt` function to save a pre-trained sentence transformer model for inferencing or benchmark with other models. \n",
    "\n",
    "The `save_as_pt`  function will prepare the model in proper format(Torch Script) along with tokenizers configuration file to upload to OpenSearch. Plese visit the [SentenceTransformerModel.save_as_pt](https://opensearch-project.github.io/opensearch-py-ml/reference/api/sentence_transformer.html#opensearch_py_ml.sentence_transformer_model.SentenceTransformerModel.save_as_pt) for API Reference . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503f8136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default to download model id, \"sentence-transformers/msmarco-distilbert-base-tas-b\" from hugging face \n",
    "# and output a model in a zip file containing model.pt file and tokenizers.json file. \n",
    "pre_trained_model = SentenceTransformerModel(folder_path = '/Volumes/workplace/upload_content/export_huggingface/', overwrite = True)\n",
    "pre_trained_model.save_as_pt(sentences = ['today is sunny'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bd0405",
   "metadata": {},
   "source": [
    "## Step 3: Upload the model to OpenSearch cluster\n",
    "After generated a model zip file, the users will need to describe model configuration in a ml-commons_model_config.json file. The `make_model_config_json` function in sentencetransformermodel class will parse the config file from hugging-face config.son file. If users would like to use a different config than the pre-trained sentence transformer, `make_model_config_json` function provide arguuments to change the configuration content and generated a ml-commons_model_config.json file. Plese visit the [SentenceTransformerModel.make_model_config_json](https://opensearch-project.github.io/opensearch-py-ml/reference/api/sentence_transformer.html#opensearch_py_ml.sentence_transformer_model.SentenceTransformerModel.make_model_config_json) for API Reference . \n",
    "\n",
    "In general, the ml common client supports uploading sentence transformer models. With a zip file contains model in  Torch Script format, and a configuration file for tokenizers in json format, the `upload_model` function connects to opensearch through ml client and upload the model. Plese visit the [MLCommonClient.upload_model](https://opensearch-project.github.io/opensearch-py-ml/reference/api/ml_commons_upload_api.html#opensearch_py_ml.ml_commons_integration.MLCommonClient.upload_model) for API Reference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbe84425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading config file from: /Volumes/workplace/upload_content/model_files/config.json\n",
      "generating ml-commons_model_config.json file...\n",
      "\n",
      "{'name': 'sentence-transformers/msmarco-distilbert-base-tas-b', 'version': 1, 'model_format': 'TORCH_SCRIPT', 'model_task_type': 'TEXT_EMBEDDING', 'model_config': {'model_type': 'distilbert', 'embedding_dimension': 768, 'framework_type': 'sentence_transformers', 'all_config': '{\"_name_or_path\": \"/Users/dhrubo/.cache/torch/sentence_transformers/sentence-transformers_msmarco-distilbert-base-tas-b/\", \"activation\": \"gelu\", \"architectures\": [\"DistilBertModel\"], \"attention_dropout\": 0.1, \"dim\": 768, \"dropout\": 0.1, \"hidden_dim\": 3072, \"initializer_range\": 0.02, \"max_position_embeddings\": 512, \"model_type\": \"distilbert\", \"n_heads\": 12, \"n_layers\": 6, \"pad_token_id\": 0, \"qa_dropout\": 0.1, \"seq_classif_dropout\": 0.2, \"sinusoidal_pos_embds\": false, \"tie_weights_\": true, \"torch_dtype\": \"float32\", \"transformers_version\": \"4.16.2\", \"vocab_size\": 30522}'}}\n",
      "ml-commons_model_config.json file is saved at :  /Volumes/workplace/upload_content/model_files/ml-commons_model_config.json\n"
     ]
    }
   ],
   "source": [
    "#users will need to prepare a ml-commons_model_config.json file to config the model, including model name ..\n",
    "#this is a helpful function in py-ml.sentence_transformer_model to generate ml-commons_model_config.json file\n",
    "custom_model.make_model_config_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce9cc2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to ml_common client with OpenSearch client\n",
    "import opensearch_py_ml as oml\n",
    "from opensearch_py_ml.ml_commons import MLCommonClient\n",
    "ml_client = MLCommonClient(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7b0ff7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks 27\n",
      "Sha1 value of the model file:  ec883a9887b9a9a468c6af2fb62a9175057f8c0e522a857a0cc4ec1f1b73733e\n",
      "Model meta data was created successfully. Model Id:  c61eMYUB385XdR-p0PTN\n",
      "uploading chunk 1 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 2 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 3 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 4 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 5 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 6 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 7 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 8 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 9 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 10 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 11 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 12 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 13 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 14 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 15 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 16 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 17 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 18 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 19 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 20 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 21 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 22 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 23 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 24 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 25 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 26 of 27\n",
      "{'status': 'Uploaded'}\n",
      "uploading chunk 27 of 27\n",
      "{'status': 'Uploaded'}\n",
      "Model uploaded successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c61eMYUB385XdR-p0PTN'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload model to OpenSearch cluster, using model zip file path and ml-commons_model_config.json file generated above\n",
    "\n",
    "model_path = '/Volumes/workplace/upload_content/model_files/test2_model.zip'\n",
    "model_config_path = '/Volumes/workplace/upload_content/model_files/ml-commons_model_config.json'\n",
    "ml_client.upload_model( model_path, model_config_path, isVerbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28e9310c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_id': 'dK1gMYUB385XdR-pnfQL', 'status': 'CREATED'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can load the uploaded model into memory by using the model id.\n",
    "\n",
    "\n",
    "ml_client.load_model(\"c61eMYUB385XdR-p0PTN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d6b1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}