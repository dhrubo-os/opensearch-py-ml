

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Demo Notebook for Sentence Transformer Model Training, Saving and Uploading to OpenSearch &mdash; Opensearch-py-ml 1.0.0b1 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/plot_directive.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Demo Notebook for MLCommons Integration" href="demo_ml_commons_integration.html" />
    <link rel="prev" title="Online Retail analysis" href="online_retail_analysis.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Opensearch-py-ml
          

          
          </a>

          
            
            
              <div class="version">
                1.0.0b1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../reference/index.html">API Reference</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="demo_notebook.html">Demo Notebook for Dataframe</a></li>
<li class="toctree-l2"><a class="reference internal" href="online_retail_analysis.html">Online Retail analysis</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Demo Notebook for Sentence Transformer Model Training, Saving and Uploading to OpenSearch</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Introduction">Introduction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Passage-retrieval">Passage retrieval</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Synthetic-query-generation">Synthetic query generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Train-BERT-Model-with-synthetic-query-data">Train BERT Model with synthetic query data</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Step-1:-Import-packages,-set-up-client-and-define-helper-functions">Step 1: Import packages, set up client and define helper functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Step-2:-Import-the-data/passages-for-synthetic-query-generation">Step 2: Import the data/passages for synthetic query generation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#2.1)-Load-the-data-and-convert-into-a-pandas-dataframe">2.1) Load the data and convert into a pandas dataframe</a></li>
<li class="toctree-l4"><a class="reference internal" href="#2.2)-Convert-the-data-into-a-list-of-strings-and-instantiate-an-object-of-the-class-Synthetic_Query_Generation">2.2) Convert the data into a list of strings and instantiate an object of the class Synthetic_Query_Generation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Step-3:-Generate-synthetic-queries">Step 3: Generate synthetic queries</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#This-is-how-the-sample-queries-look-like,">This is how the sample queries look like,</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#Step-4:-Read-synthetic-queries-and-train/fine-tune-a-hugging-face-sentence-transformer-model-on-synthetic-data">Step 4: Read synthetic queries and train/fine-tune a hugging face sentence transformer model on synthetic data</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Step-5:-(Optional)-Save-model">Step 5: (Optional) Save model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Step-6:-Upload-the-model-to-OpenSearch-cluster">Step 6: Upload the model to OpenSearch cluster</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="demo_ml_commons_integration.html">Demo Notebook for MLCommons Integration</a></li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Opensearch-py-ml</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="index.html">Examples</a> &raquo;</li>
        
      <li>Demo Notebook for Sentence Transformer Model Training, Saving and Uploading to OpenSearch</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/examples/demo_transformer_model_train_save_upload_to_openSearch.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars and line breaks on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
    white-space: pre;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="Demo-Notebook-for-Sentence-Transformer-Model-Training,-Saving-and-Uploading-to-OpenSearch">
<h1>Demo Notebook for Sentence Transformer Model Training, Saving and Uploading to OpenSearch<a class="headerlink" href="#Demo-Notebook-for-Sentence-Transformer-Model-Training,-Saving-and-Uploading-to-OpenSearch" title="Permalink to this heading">¶</a></h1>
<section id="Introduction">
<h2>Introduction<a class="headerlink" href="#Introduction" title="Permalink to this heading">¶</a></h2>
<p>Deep learning models are very powerful and have been shown to improve state-of-the-art for several tasks. However, they need a lot of labelled training data. Such data is often hard to obtain. In this notebook, we show how pre-trained large language models can be used to circumvent this issue. We introduce the technique of synthetic data generation and use it obtain a transformer model that is custom built for a given set of documents for the task of search.</p>
<section id="Passage-retrieval">
<h3>Passage retrieval<a class="headerlink" href="#Passage-retrieval" title="Permalink to this heading">¶</a></h3>
<p>We focus on the task of passage retrieval i.e the corpus consists of passages, and it is searched at run-time given a user query. A passage could be any piece of unstructured text such as sentences, documents or webpages.</p>
<p>Deep neural networks such as transformers have been shown to give state-of-the-art results for the task of passage/document retireval given large enough labelled dataset. For passage retrieval a labelled dataset would consist of (query, relevant passage) pairs.</p>
<p>Labelled datasets such as MS Marco and Natural questions consist of more than 500K (query, passage) pairs and can be used to train transfomers. However transformers trained on these datasets have limited performance on out-of-domain datasets <a class="reference external" href="https://arxiv.org/abs/2104.08663">https://arxiv.org/abs/2104.08663</a>. This is a well know fact – medium sized transformers have toruble generalizing on out-of-distribution data. Thus to use transformers for search we need domain specific labelled data. Unfortunately such data is not generally
avaialable and is hard to acquire.</p>
</section>
<section id="Synthetic-query-generation">
<h3>Synthetic query generation<a class="headerlink" href="#Synthetic-query-generation" title="Permalink to this heading">¶</a></h3>
<p>In the absence of such labelled data we provide a synthetic query generator (SQG) model that can be used to create synthetic queries given a passage. The SQG model is a large transformer model that has been trained to generate human like queries given a passage. It can be used to create a labelled dataset of (synthetic queries, passage). A transformer model can be trained on this synthetic data and used for semantic search. In fact, we have shown that such synthetically trained models beat the
current state-of-the-art.</p>
</section>
<section id="Train-BERT-Model-with-synthetic-query-data">
<h3>Train BERT Model with synthetic query data<a class="headerlink" href="#Train-BERT-Model-with-synthetic-query-data" title="Permalink to this heading">¶</a></h3>
<p>After generating synthetic query we can train Sentence Transformer model to get more precise embedding.</p>
<p>This notebook provides a walkthrough guidance for users use their synthetic queries to fine tune and train a sentence transformer model. In this notebook, you use opensearch_py_ml to accomplish the following:</p>
<p>Step 1: Import packages and set up client</p>
<p>Step 2: Import the data/passages for synthetic query generation</p>
<p>Step 3: Generate Synthetic Queries</p>
<p>Step 4: Read synthetic queries and train/fine-tune model using a hugging face sentence transformer model</p>
<p>Step 5: (Optional) Save model</p>
<p>Step 6: Upload the model to OpenSearch cluster</p>
</section>
</section>
<section id="Step-1:-Import-packages,-set-up-client-and-define-helper-functions">
<h2>Step 1: Import packages, set up client and define helper functions<a class="headerlink" href="#Step-1:-Import-packages,-set-up-client-and-define-helper-functions" title="Permalink to this heading">¶</a></h2>
<p>Install required packages for opensearch_py_ml.sentence_transformer_model Install <code class="docutils literal notranslate"><span class="pre">opensearchpy</span></code> and <code class="docutils literal notranslate"><span class="pre">opensearch-py-ml</span></code> through pypi</p>
<p>generate.py script is released with the Synthetic Query Generation model.</p>
<p>Please refer <a class="reference external" href="https://pytorch.org/">https://pytorch.org/</a> to proper install torch based on your environment setting.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># pip install pandas matplotlib numpy torch accelerate sentence_transformers tqdm transformers opensearch-py opensearch-py-ml detoxify datasets</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">opensearch_py_ml</span> <span class="k">as</span> <span class="nn">oml</span>
<span class="kn">from</span> <span class="nn">opensearchpy</span> <span class="kn">import</span> <span class="n">OpenSearch</span>
<span class="kn">import</span> <span class="nn">generate</span> <span class="c1"># generate.py script is release with the</span>
<span class="kn">from</span> <span class="nn">generate</span> <span class="kn">import</span> <span class="n">Synthetic_Query_Generation</span>
<span class="kn">from</span> <span class="nn">opensearch_py_ml.ml_models</span> <span class="kn">import</span> <span class="n">SentenceTransformerModel</span>
<span class="kn">import</span> <span class="nn">boto3</span><span class="o">,</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span><span class="o">,</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">import</span> <span class="nn">gc</span><span class="o">,</span> <span class="nn">torch</span>
<span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import mlcommon to later upload the model to OpenSearch Cluster</span>
<span class="kn">from</span> <span class="nn">opensearch_py_ml.ml_commons</span> <span class="kn">import</span> <span class="n">MLCommonClient</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">CLUSTER_URL</span> <span class="o">=</span> <span class="s1">&#39;https://localhost:9200&#39;</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_os_client</span><span class="p">(</span><span class="n">cluster_url</span> <span class="o">=</span> <span class="n">CLUSTER_URL</span><span class="p">,</span>
                  <span class="n">username</span><span class="o">=</span><span class="s1">&#39;admin&#39;</span><span class="p">,</span>
                  <span class="n">password</span><span class="o">=</span><span class="s1">&#39;admin&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Get OpenSearch client</span>
<span class="sd">    :param cluster_url: cluster URL like https://ml-te-netwo-1s12ba42br23v-ff1736fa7db98ff2.elb.us-west-2.amazonaws.com:443</span>
<span class="sd">    :return: OpenSearch client</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">OpenSearch</span><span class="p">(</span>
        <span class="n">hosts</span><span class="o">=</span><span class="p">[</span><span class="n">cluster_url</span><span class="p">],</span>
        <span class="n">http_auth</span><span class="o">=</span><span class="p">(</span><span class="n">username</span><span class="p">,</span> <span class="n">password</span><span class="p">),</span>
        <span class="n">verify_certs</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">client</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">client</span> <span class="o">=</span> <span class="n">get_os_client</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">myselect</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;passages&quot;</span><span class="p">][</span><span class="s2">&quot;is_selected&quot;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="s2">&quot;passages&quot;</span><span class="p">][</span><span class="s2">&quot;passage_text&quot;</span><span class="p">][</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;passages&quot;</span><span class="p">][</span><span class="s2">&quot;is_selected&quot;</span><span class="p">])]</span>
    <span class="k">return</span> <span class="s2">&quot;-1&quot;</span>
</pre></div>
</div>
</div>
</section>
<section id="Step-2:-Import-the-data/passages-for-synthetic-query-generation">
<h2>Step 2: Import the data/passages for synthetic query generation<a class="headerlink" href="#Step-2:-Import-the-data/passages-for-synthetic-query-generation" title="Permalink to this heading">¶</a></h2>
<p>There are three supported options to read datasets : * Option 1: read from a local data folder in jsonl file * Option 2: read from a list of passages * Option 3: read from OpenSearch client by index_name</p>
<p>For the purpose of this notebook we will demonstrate option 2: read from a list of passages.</p>
<p>We take the MS Marco dataset of passages as our example dataset.</p>
<section id="2.1)-Load-the-data-and-convert-into-a-pandas-dataframe">
<h3>2.1) Load the data and convert into a pandas dataframe<a class="headerlink" href="#2.1)-Load-the-data-and-convert-into-a-pandas-dataframe" title="Permalink to this heading">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;ms_marco&quot;</span><span class="p">,</span><span class="s2">&quot;v1.1&quot;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Reusing dataset ms_marco (/Users/dhrubo/.cache/huggingface/datasets/ms_marco/v1.1/1.1.0/b6a62715fa5219aea5275dd3556601004cd63945cb63e36e022f77bb3cbbca84)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "f214b68bd52d45efab430b7a6c132240", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;passage&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">myselect</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s2">&quot;query&quot;</span><span class="p">,</span><span class="s2">&quot;passage&quot;</span><span class="p">]][</span><span class="n">df</span><span class="o">.</span><span class="n">passage</span> <span class="o">!=</span> <span class="s2">&quot;-1&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>The above cells create a dataframe that consists of queries and passages</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Setting print options to display full columns</span>

<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_columns&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.expand_frame_repr&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;max_colwidth&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The dataset looks like,</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>query</th>
      <th>passage</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>walgreens store sales average</td>
      <td>The average Walgreens salary ranges from approximately $15,000 per year for Customer Service Associate / Cashier to $179,900 per year for District Manager. Average Walgreens hourly pay ranges from approximately $7.35 per hour for Laboratory Technician to $68.90 per hour for Pharmacy Manager. Salary information comes from 7,810 data points collected directly from employees, users, and jobs on Indeed.</td>
    </tr>
    <tr>
      <th>1</th>
      <td>how much do bartenders make</td>
      <td>According to the Bureau of Labor Statistics, the average hourly wage for a bartender is $10.36, and the average yearly take-home is $21,550. Bartending can be a lot of things. For some it is exciting, for others exhausting. At times there is a lot of fun to be had, at others it is rather dull. But for the most part, bartending is almost always rewarding in the financial sense, as long as you stick with it.</td>
    </tr>
    <tr>
      <th>2</th>
      <td>what is a furuncle boil</td>
      <td>A boil, also called a furuncle, is a deep folliculitis, infection of the hair follicle. It is most commonly caused by infection by the bacterium Staphylococcus aureus, resulting in a painful swollen area on the skin caused by an accumulation of pus and dead tissue. Signs and symptoms [edit]. Boils are bumpy, red, pus-filled lumps around a hair follicle that are tender, warm, and very painful. They range from pea-sized to golf ball-sized. A yellow or white point at the center of the lump can be seen when the boil is ready to drain or discharge pus.</td>
    </tr>
    <tr>
      <th>3</th>
      <td>what can urinalysis detect</td>
      <td>Urinalysis is a test that evaluates a sample of your urine. Urinalysis is used to detect and assess a wide range of disorders, such as urinary tract infection, kidney disease and diabetes. Urinalysis involves examining the appearance, concentration and content of urine. Abnormal urinalysis results may point to a disease or illness. For example, a urinary tract infection can make urine look cloudy instead of clear. Increased levels of protein in urine can be a sign of kidney disease.</td>
    </tr>
    <tr>
      <th>4</th>
      <td>what is vitamin a used for</td>
      <td>Vitamin A is also used for shigellosis, diseases of the nervous system, nose infections, loss of sense of smell, asthma, persistent headaches, kidney stones, overactive thyroid, iron-poor blood (anemia), deafness, ringing in the ears, and precancerous mouth sores (leukoplakia). It can also be made in a laboratory. Vitamin A is used for treating vitamin A deficiency. It is also used to reduce complications of diseases such as malaria, HIV, measles, and diarrhea in children with</td>
    </tr>
    <tr>
      <th>5</th>
      <td>what causes genetic alterations in normal cells</td>
      <td>The initiation of cell transformation is generally associated with genetic alterations in normal cells that lead to the loss of intercellular-and/or extracellular-matrix- (ECM-) mediated cell adhesion. Cancer afflicts an organ or a tissue by inducing abnormal and uncontrolled division of cells that either constitute it or migrate to it. At the cellular level, this is caused by genetic alterations in networks that regulate cell division and cell death.</td>
    </tr>
    <tr>
      <th>6</th>
      <td>cost to frame basement</td>
      <td>Our free calculator uses recent, trusted data to estimate costs for your Basement Wall Framing project. For a basic 125 square feet project in zip code 47474, the benchmark cost to Frame Basement Walls ranges between $2.51 - $3.17 per square foot* . To estimate costs for your project:</td>
    </tr>
    <tr>
      <th>7</th>
      <td>erudite divergent definition</td>
      <td>The smart ones, the ones value knowledge and logic are Erudite. They know everything. . Erudite is one of the five factions in the world of Divergent, the one and only faction dedicated to knowledge, intelligence, curiosity, and astuteness. It was formed by those who blamed ignorance for the war that had occurred in the past, causing them to split into factions in the first place. They also use Dauntless as their soldiers near the end of Divergent. They have a close relationship with Amity, but Amity are not involved in the war because they are the peace faction. No relationship is stated between Erudite and Candor.</td>
    </tr>
    <tr>
      <th>8</th>
      <td>why is albumin normally absent in urine</td>
      <td>Share. Albumin is a protein present in the blood. Proteins are normally absent in urine because the kidney cells generally prevent large molecules including proteins, from being excreted. Some proteins may appear in the urine in normal individuals also if blood levels are very high. In kidney diseases, albumin will appear in the urine even with normal blood levels.</td>
    </tr>
    <tr>
      <th>9</th>
      <td>where was movie the birds filmed</td>
      <td>The Birds filming location: the Schoolhouse: Bodega Lane, Bodega, Northern California. Alfred Hitchcock ’s film of the Daphne du Maurier short story (originally set in Cornwall, England) uses lots of process (special effects) shots but, as usual, the director plays fair with the geography. The Birds filming location: the restaurant: Tides Wharf and Restaurant, Bodega Bay, Northern California. The Tides Wharf &amp; Restaurant, in which the assorted locals shelter from the bird attacks, has expanded into an unrecognisable hotel complex since the film was made. The big surprise is that there is no town.</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>The MS Marco dataset has real queries for passages but we will pretend that it does not and generate synthetic queries for each passage</p>
</section>
<section id="2.2)-Convert-the-data-into-a-list-of-strings-and-instantiate-an-object-of-the-class-Synthetic_Query_Generation">
<h3>2.2) Convert the data into a list of strings and instantiate an object of the class Synthetic_Query_Generation<a class="headerlink" href="#2.2)-Convert-the-data-into-a-list-of-strings-and-instantiate-an-object-of-the-class-Synthetic_Query_Generation" title="Permalink to this heading">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_passages</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">passage</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ss</span> <span class="o">=</span> <span class="n">Synthetic_Query_Generation</span><span class="p">(</span><span class="n">sentences</span> <span class="o">=</span> <span class="n">sample_passages</span><span class="p">[:</span><span class="mi">8</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
</pre></div></div>
</div>
</section>
</section>
<section id="Step-3:-Generate-synthetic-queries">
<h2>Step 3: Generate synthetic queries<a class="headerlink" href="#Step-3:-Generate-synthetic-queries" title="Permalink to this heading">¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">three_step_query</span> <span class="o">=</span> <span class="n">ss</span><span class="o">.</span><span class="n">generate_synthetic_queries</span><span class="p">(</span><span class="n">num_machines</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                                                 <span class="n">overwrite</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                                                 <span class="n">total_queries</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
                                                 <span class="n">numseq</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
                                                 <span class="n">num_gpu</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                                                 <span class="n">toxic_cutoff</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Tokenizing corpus...
Preparing input_ids and attention_mask...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|██████████| 8/8 [00:00&lt;00:00, 424.24it/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0 number of documents out of 8 are longer than 512 tokens and were discarded
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
The number of steps for creating queries:  8
Running on CPU...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|██████████| 8/8 [03:25&lt;00:00, 25.68s/it]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
The total number of synthetic queries before detoxify is 80
68good queries are kept after detoxify.
File is saved to /Volumes/workplace/opensearch-py-ml/src/opensearch-py-ml/queries_after_detoxify/synthetic_queries_batch_.p file.
Zip file is saved to/Volumes/workplace/opensearch-py-ml/src/opensearch-py-ml/clean_synthetic_queries.zip
</pre></div></div>
</div>
<p>A lot of actions are being executed in the above cell. We elaborate them step by step,</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>1) Convert the data into a form that can be consumed by the Synthetic query generator (SQG) model. This amounts to tokenizing the data using a tokenizer. The SQG model is a fine-tuned version of the GPT-XL model https://huggingface.co/gpt2-xl and the tokenizer is the GPT tokenizer.

2) The tokenizer has a max input length of 512 tokens. Every passage is tokenized with the special tokens &lt;|startoftext|&gt; and QRY: appended to the beginning and the end of every passage respectively.

3) Load the SQG model i.e. 1.5B parameter GPT2-XL model that has been trained to ask questions given passages. This model has been made publicly available and can be found here https://ci.opensearch.org/ci/dbc/models/ml-models/amazon/gpt/GPT2_xl_sqg/1.0.0/GPT2_xl_sqg.zip.

4) Once the model has been loaded and the data has been tokenized, the model starts the process of query generation. &quot;total_queries&quot; is number of synthetic queries generated for every passage and &quot;numseq&quot; is the number of queries that are generated by a model at a given time. Ideally total_queries = numseq, but this can lead to out of memory issues. So set numseq to an integer that is around 10 or less, and is a divisor of total_queries.

It also needs the number of GPUs and the number of machines/nodes that it can use. Since we are using a single node instance with no GPUs we pass 0 and 1 to the function.

5) The function now begins to generate queries and displays a progress bar. We create total_queries per passage. Empirically we find that generating more queries leads to better peformance but there are diminishing returns since the total inference time increases with total_queries.

6) After generating the queries, the function uses a publicly available package called Detoxify to remove innappropriate queries from the dataset. &quot;toxic_cutoff&quot; is a float. The script rejects all queries that have a toicity score greater than toxic_cutoff

7) Finally, the synthetic queries along with their corresponding passages are saved in a zipped file in the current working directory.
</pre></div>
</div>
<section id="This-is-how-the-sample-queries-look-like,">
<h3>This is how the sample queries look like,<a class="headerlink" href="#This-is-how-the-sample-queries-look-like," title="Permalink to this heading">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># initiate SentenceTransformerModel object</span>

<span class="n">custom_model</span> <span class="o">=</span> <span class="n">SentenceTransformerModel</span><span class="p">(</span><span class="n">folder_path</span><span class="o">=</span><span class="s2">&quot;/Volumes/workplace/upload_content/model_files/&quot;</span><span class="p">,</span> <span class="n">overwrite</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>



<span class="n">df</span> <span class="o">=</span> <span class="n">custom_model</span><span class="o">.</span><span class="n">read_queries</span><span class="p">(</span><span class="n">read_path</span> <span class="o">=</span> <span class="s1">&#39;/Volumes/workplace/upload_content/clean_synthetic_queries.zip&#39;</span><span class="p">,</span> <span class="n">overwrite</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="n">df</span><span class="p">[::</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Reading synthetic query file: /Volumes/workplace/upload_content/model_files/synthetic_queries/synthetic_queries_batch.p

</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>prob</th>
      <th>query</th>
      <th>passages</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>11</th>
      <td>0.000058</td>
      <td>what is the salary range for a bb bar</td>
      <td>According to the Bureau of Labor Statistics, the average hourly wage for a bartender is $10.36, and the average yearly take-home is $21,550. Bartending can be a lot of things. For some it is exciting, for others exhausting. At times there is a lot of fun to be had, at others it is rather dull. But for the most part, bartending is almost always rewarding in the financial sense, as long as you stick with it.</td>
    </tr>
    <tr>
      <th>67</th>
      <td>0.000027</td>
      <td>are divergent known for their science</td>
      <td>The smart ones, the ones value knowledge and logic are Erudite. They know everything.. Erudite is one of the five factions in the world of Divergent, the one and only faction dedicated to knowledge, intelligence, curiosity, and astuteness. It was formed by those who blamed ignorance for the war that had occurred in the past, causing them to split into factions in the first place. They also use Dauntless as their soldiers near the end of Divergent. They have a close relationship with Amity, but Amity are not involved in the war because they are the peace faction. No relationship is stated between Erudite and Candor.</td>
    </tr>
    <tr>
      <th>33</th>
      <td>0.000088</td>
      <td>what diseases do urinalis tests show</td>
      <td>Urinalysis is a test that evaluates a sample of your urine. Urinalysis is used to detect and assess a wide range of disorders, such as urinary tract infection, kidney disease and diabetes. Urinalysis involves examining the appearance, concentration and content of urine. Abnormal urinalysis results may point to a disease or illness. For example, a urinary tract infection can make urine look cloudy instead of clear. Increased levels of protein in urine can be a sign of kidney disease.</td>
    </tr>
    <tr>
      <th>46</th>
      <td>0.000001</td>
      <td>what is a primary role for growth factors?</td>
      <td>The initiation of cell transformation is generally associated with genetic alterations in normal cells that lead to the loss of intercellular-and/or extracellular-matrix- (ECM-) mediated cell adhesion. Cancer afflicts an organ or a tissue by inducing abnormal and uncontrolled division of cells that either constitute it or migrate to it. At the cellular level, this is caused by genetic alterations in networks that regulate cell division and cell death.</td>
    </tr>
    <tr>
      <th>49</th>
      <td>0.000610</td>
      <td>definition of initiation of gene expression</td>
      <td>The initiation of cell transformation is generally associated with genetic alterations in normal cells that lead to the loss of intercellular-and/or extracellular-matrix- (ECM-) mediated cell adhesion. Cancer afflicts an organ or a tissue by inducing abnormal and uncontrolled division of cells that either constitute it or migrate to it. At the cellular level, this is caused by genetic alterations in networks that regulate cell division and cell death.</td>
    </tr>
    <tr>
      <th>0</th>
      <td>5.286169</td>
      <td>how much does walgreen assistant manager make</td>
      <td>The average Walgreens salary ranges from approximately $15,000 per year for Customer Service Associate / Cashier to $179,900 per year for District Manager. Average Walgreens hourly pay ranges from approximately $7.35 per hour for Laboratory Technician to $68.90 per hour for Pharmacy Manager. Salary information comes from 7,810 data points collected directly from employees, users, and jobs on Indeed.</td>
    </tr>
    <tr>
      <th>65</th>
      <td>0.100414</td>
      <td>what kind of people make up divergent</td>
      <td>The smart ones, the ones value knowledge and logic are Erudite. They know everything.. Erudite is one of the five factions in the world of Divergent, the one and only faction dedicated to knowledge, intelligence, curiosity, and astuteness. It was formed by those who blamed ignorance for the war that had occurred in the past, causing them to split into factions in the first place. They also use Dauntless as their soldiers near the end of Divergent. They have a close relationship with Amity, but Amity are not involved in the war because they are the peace faction. No relationship is stated between Erudite and Candor.</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</section>
</section>
<section id="Step-4:-Read-synthetic-queries-and-train/fine-tune-a-hugging-face-sentence-transformer-model-on-synthetic-data">
<h2>Step 4: Read synthetic queries and train/fine-tune a hugging face sentence transformer model on synthetic data<a class="headerlink" href="#Step-4:-Read-synthetic-queries-and-train/fine-tune-a-hugging-face-sentence-transformer-model-on-synthetic-data" title="Permalink to this heading">¶</a></h2>
<p>With a synthetic queries zip file, users can fine tune a sentence transformer model.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">SentenceTransformerModel</span></code> class will inititate an object for training, exporting and configuring the model. Plese visit the <a class="reference external" href="https://opensearch-project.github.io/opensearch-py-ml/reference/api/sentence_transformer.html#opensearch_py_ml.sentence_transformer_model.SentenceTransformerModel">SentenceTransformerModel</a> for API Reference .</p>
<p>The <code class="docutils literal notranslate"><span class="pre">train</span></code> function will import synthestic queries, load sentence transformer example and train the model using a hugging face sentence transformer model. Plese visit the <a class="reference external" href="https://opensearch-project.github.io/opensearch-py-ml/reference/api/sentence_transformer.html#opensearch_py_ml.sentence_transformer_model.SentenceTransformerModel.train">SentenceTransformerModel.train</a> for API Reference .</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># clean up cache before training to free up spaces</span>
<span class="kn">import</span> <span class="nn">gc</span><span class="o">,</span> <span class="nn">torch</span>

<span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>

<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><br/><span></span><span class="n">training</span> <span class="o">=</span> <span class="n">custom_model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">read_path</span> <span class="o">=</span> <span class="s1">&#39;/Volumes/workplace/upload_content/clean_synthetic_queries.zip&#39;</span><span class="p">,</span>
                        <span class="n">output_model_name</span> <span class="o">=</span> <span class="s1">&#39;test2_model.pt&#39;</span><span class="p">,</span>
                        <span class="n">zip_file_name</span><span class="o">=</span> <span class="s1">&#39;test2_model.zip&#39;</span><span class="p">,</span>
                        <span class="n">overwrite</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                        <span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                        <span class="n">verbose</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Reading synthetic query file: /Volumes/workplace/upload_content/model_files/synthetic_queries/synthetic_queries_batch.p

Loading training examples...

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|██████████| 66/66 [00:00&lt;00:00, 244544.23it/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Start training without accelerator...

The number of training epoch are 1

The total number of steps per training epoch are 2

Training epoch 0...

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|██████████| 2/2 [00:10&lt;00:00,  5.44s/it]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Total training time: 11.379661083221436

Model saved to path: /Volumes/workplace/upload_content/model_files/

tokenizer_json_path:  /Volumes/workplace/upload_content/model_files/tokenizer.json
zip file is saved to /Volumes/workplace/upload_content/model_files/test2_model.zip

</pre></div></div>
</div>
</section>
<section id="Step-5:-(Optional)-Save-model">
<h2>Step 5: (Optional) Save model<a class="headerlink" href="#Step-5:-(Optional)-Save-model" title="Permalink to this heading">¶</a></h2>
<p>If following step 1, the model zip will be auto generated, and the print message will indicate the zip file path as shown above.</p>
<p>But if using other pretrained sentence transformer model from Hugging face, users can use <code class="docutils literal notranslate"><span class="pre">save_as_pt</span></code> function to save a pre-trained sentence transformer model for inferencing or benchmark with other models.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">save_as_pt</span></code> function will prepare the model in proper format(Torch Script) along with tokenizers configuration file to upload to OpenSearch. Plese visit the <a class="reference external" href="https://opensearch-project.github.io/opensearch-py-ml/reference/api/sentence_transformer.html#opensearch_py_ml.sentence_transformer_model.SentenceTransformerModel.save_as_pt">SentenceTransformerModel.save_as_pt</a> for API Reference .</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># default to download model id, &quot;sentence-transformers/msmarco-distilbert-base-tas-b&quot; from hugging face</span>
<span class="c1"># and output a model in a zip file containing model.pt file and tokenizers.json file.</span>
<span class="n">pre_trained_model</span> <span class="o">=</span> <span class="n">SentenceTransformerModel</span><span class="p">(</span><span class="n">folder_path</span> <span class="o">=</span> <span class="s1">&#39;/Volumes/workplace/upload_content/export_huggingface/&#39;</span><span class="p">,</span> <span class="n">overwrite</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">pre_trained_model</span><span class="o">.</span><span class="n">save_as_pt</span><span class="p">(</span><span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;today is sunny&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
model file is saved to  /Volumes/workplace/upload_content/export_huggingface/msmarco-distilbert-base-tas-b.pt
zip file is saved to  /Volumes/workplace/upload_content/export_huggingface/msmarco-distilbert-base-tas-b.zip

</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
SentenceTransformer(
  original_name=SentenceTransformer
  (0): Transformer(
    original_name=Transformer
    (auto_model): DistilBertModel(
      original_name=DistilBertModel
      (embeddings): Embeddings(
        original_name=Embeddings
        (word_embeddings): Embedding(original_name=Embedding)
        (position_embeddings): Embedding(original_name=Embedding)
        (LayerNorm): LayerNorm(original_name=LayerNorm)
        (dropout): Dropout(original_name=Dropout)
      )
      (transformer): Transformer(
        original_name=Transformer
        (layer): ModuleList(
          original_name=ModuleList
          (0): TransformerBlock(
            original_name=TransformerBlock
            (attention): MultiHeadSelfAttention(
              original_name=MultiHeadSelfAttention
              (dropout): Dropout(original_name=Dropout)
              (q_lin): Linear(original_name=Linear)
              (k_lin): Linear(original_name=Linear)
              (v_lin): Linear(original_name=Linear)
              (out_lin): Linear(original_name=Linear)
            )
            (sa_layer_norm): LayerNorm(original_name=LayerNorm)
            (ffn): FFN(
              original_name=FFN
              (dropout): Dropout(original_name=Dropout)
              (lin1): Linear(original_name=Linear)
              (lin2): Linear(original_name=Linear)
            )
            (output_layer_norm): LayerNorm(original_name=LayerNorm)
          )
          (1): TransformerBlock(
            original_name=TransformerBlock
            (attention): MultiHeadSelfAttention(
              original_name=MultiHeadSelfAttention
              (dropout): Dropout(original_name=Dropout)
              (q_lin): Linear(original_name=Linear)
              (k_lin): Linear(original_name=Linear)
              (v_lin): Linear(original_name=Linear)
              (out_lin): Linear(original_name=Linear)
            )
            (sa_layer_norm): LayerNorm(original_name=LayerNorm)
            (ffn): FFN(
              original_name=FFN
              (dropout): Dropout(original_name=Dropout)
              (lin1): Linear(original_name=Linear)
              (lin2): Linear(original_name=Linear)
            )
            (output_layer_norm): LayerNorm(original_name=LayerNorm)
          )
          (2): TransformerBlock(
            original_name=TransformerBlock
            (attention): MultiHeadSelfAttention(
              original_name=MultiHeadSelfAttention
              (dropout): Dropout(original_name=Dropout)
              (q_lin): Linear(original_name=Linear)
              (k_lin): Linear(original_name=Linear)
              (v_lin): Linear(original_name=Linear)
              (out_lin): Linear(original_name=Linear)
            )
            (sa_layer_norm): LayerNorm(original_name=LayerNorm)
            (ffn): FFN(
              original_name=FFN
              (dropout): Dropout(original_name=Dropout)
              (lin1): Linear(original_name=Linear)
              (lin2): Linear(original_name=Linear)
            )
            (output_layer_norm): LayerNorm(original_name=LayerNorm)
          )
          (3): TransformerBlock(
            original_name=TransformerBlock
            (attention): MultiHeadSelfAttention(
              original_name=MultiHeadSelfAttention
              (dropout): Dropout(original_name=Dropout)
              (q_lin): Linear(original_name=Linear)
              (k_lin): Linear(original_name=Linear)
              (v_lin): Linear(original_name=Linear)
              (out_lin): Linear(original_name=Linear)
            )
            (sa_layer_norm): LayerNorm(original_name=LayerNorm)
            (ffn): FFN(
              original_name=FFN
              (dropout): Dropout(original_name=Dropout)
              (lin1): Linear(original_name=Linear)
              (lin2): Linear(original_name=Linear)
            )
            (output_layer_norm): LayerNorm(original_name=LayerNorm)
          )
          (4): TransformerBlock(
            original_name=TransformerBlock
            (attention): MultiHeadSelfAttention(
              original_name=MultiHeadSelfAttention
              (dropout): Dropout(original_name=Dropout)
              (q_lin): Linear(original_name=Linear)
              (k_lin): Linear(original_name=Linear)
              (v_lin): Linear(original_name=Linear)
              (out_lin): Linear(original_name=Linear)
            )
            (sa_layer_norm): LayerNorm(original_name=LayerNorm)
            (ffn): FFN(
              original_name=FFN
              (dropout): Dropout(original_name=Dropout)
              (lin1): Linear(original_name=Linear)
              (lin2): Linear(original_name=Linear)
            )
            (output_layer_norm): LayerNorm(original_name=LayerNorm)
          )
          (5): TransformerBlock(
            original_name=TransformerBlock
            (attention): MultiHeadSelfAttention(
              original_name=MultiHeadSelfAttention
              (dropout): Dropout(original_name=Dropout)
              (q_lin): Linear(original_name=Linear)
              (k_lin): Linear(original_name=Linear)
              (v_lin): Linear(original_name=Linear)
              (out_lin): Linear(original_name=Linear)
            )
            (sa_layer_norm): LayerNorm(original_name=LayerNorm)
            (ffn): FFN(
              original_name=FFN
              (dropout): Dropout(original_name=Dropout)
              (lin1): Linear(original_name=Linear)
              (lin2): Linear(original_name=Linear)
            )
            (output_layer_norm): LayerNorm(original_name=LayerNorm)
          )
        )
      )
    )
  )
  (1): Pooling(original_name=Pooling)
)
</pre></div></div>
</div>
</section>
<section id="Step-6:-Upload-the-model-to-OpenSearch-cluster">
<h2>Step 6: Upload the model to OpenSearch cluster<a class="headerlink" href="#Step-6:-Upload-the-model-to-OpenSearch-cluster" title="Permalink to this heading">¶</a></h2>
<p>After generated a model zip file, the users will need to describe model configuration in a ml-commons_model_config.json file. The <code class="docutils literal notranslate"><span class="pre">make_model_config_json</span></code> function in sentencetransformermodel class will parse the config file from hugging-face config.son file. If users would like to use a different config than the pre-trained sentence transformer, <code class="docutils literal notranslate"><span class="pre">make_model_config_json</span></code> function provide arguuments to change the configuration content and generated a ml-commons_model_config.json file. Plese
visit the <a class="reference external" href="https://opensearch-project.github.io/opensearch-py-ml/reference/api/sentence_transformer.html#opensearch_py_ml.sentence_transformer_model.SentenceTransformerModel.make_model_config_json">SentenceTransformerModel.make_model_config_json</a> for API Reference .</p>
<p>In general, the ml common client supports uploading sentence transformer models. With a zip file contains model in Torch Script format, and a configuration file for tokenizers in json format, the <code class="docutils literal notranslate"><span class="pre">upload_model</span></code> function connects to opensearch through ml client and upload the model. Plese visit the <a class="reference external" href="https://opensearch-project.github.io/opensearch-py-ml/reference/api/ml_commons_upload_api.html#opensearch_py_ml.ml_commons_integration.MLCommonClient.upload_model">MLCommonClient.upload_model</a>
for API Reference.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#users will need to prepare a ml-commons_model_config.json file to config the model, including model name ..</span>
<span class="c1">#this is a helpful function in py-ml.sentence_transformer_model to generate ml-commons_model_config.json file</span>
<span class="n">custom_model</span><span class="o">.</span><span class="n">make_model_config_json</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
ml-commons_model_config.json file is saved at :  /Volumes/workplace/upload_content/model_files/ml-commons_model_config.json
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#connect to ml_common client with OpenSearch client</span>
<span class="kn">import</span> <span class="nn">opensearch_py_ml</span> <span class="k">as</span> <span class="nn">oml</span>
<span class="kn">from</span> <span class="nn">opensearch_py_ml.ml_commons</span> <span class="kn">import</span> <span class="n">MLCommonClient</span>
<span class="n">ml_client</span> <span class="o">=</span> <span class="n">MLCommonClient</span><span class="p">(</span><span class="n">client</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># upload model to OpenSearch cluster, using model zip file path and ml-commons_model_config.json file generated above</span>

<span class="n">model_path</span> <span class="o">=</span> <span class="s1">&#39;/Volumes/workplace/upload_content/model_files/test2_model.zip&#39;</span>
<span class="n">model_config_path</span> <span class="o">=</span> <span class="s1">&#39;/Volumes/workplace/upload_content/model_files/ml-commons_model_config.json&#39;</span>
<span class="n">ml_client</span><span class="o">.</span><span class="n">upload_model</span><span class="p">(</span> <span class="n">model_path</span><span class="p">,</span> <span class="n">model_config_path</span><span class="p">,</span> <span class="n">isVerbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Total number of chunks 27
Sha1 value of the model file:  1a198957ec8a759e83f1e862ad46bb120c6c1b5a031e75c415c1a893c87a3da7
Model meta data was created successfully. Model Id:  cz2RloUB6UQeRtfO8Jph
uploading chunk 1 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 2 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 3 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 4 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 5 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 6 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 7 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 8 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 9 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 10 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 11 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 12 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 13 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 14 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 15 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 16 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 17 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 18 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 19 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 20 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 21 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 22 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 23 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 24 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 25 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 26 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 27 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
Model uploaded successfully
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&#39;cz2RloUB6UQeRtfO8Jph&#39;
</pre></div></div>
</div>
</section>
</section>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="demo_ml_commons_integration.html" class="btn btn-neutral float-right" title="Demo Notebook for MLCommons Integration" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="online_retail_analysis.html" class="btn btn-neutral float-left" title="Online Retail analysis" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2023, Opensearch.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>