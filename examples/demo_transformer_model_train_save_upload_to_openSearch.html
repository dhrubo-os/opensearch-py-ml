

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Demo Notebook for Sentence Transformer Model Training, Saving and Uploading to OpenSearch &mdash; Opensearch-py-ml 1.0.0b1 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/plot_directive.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Online Retail analysis" href="online_retail_analysis.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Opensearch-py-ml
          

          
          </a>

          
            
            
              <div class="version">
                1.0.0b1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../reference/index.html">API Reference</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="demo_notebook.html">Demo Notebook for Dataframe</a></li>
<li class="toctree-l2"><a class="reference internal" href="online_retail_analysis.html">Online Retail analysis</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Demo Notebook for Sentence Transformer Model Training, Saving and Uploading to OpenSearch</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Step-0:-Import-packages-and-set-up-client">Step 0: Import packages and set up client</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Step-1:-Read-synthetic-queries-and-train/fine-tune-model-using-a-hugging-face-sentence-transformer-model">Step 1: Read synthetic queries and train/fine-tune model using a hugging face sentence transformer model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Step-2:-(Optional)-Save-model">Step 2: (Optional) Save model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#Step-3:-Upload-the-model-to-OpenSearch-cluster">Step 3: Upload the model to OpenSearch cluster</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Opensearch-py-ml</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="index.html">Examples</a> &raquo;</li>
        
      <li>Demo Notebook for Sentence Transformer Model Training, Saving and Uploading to OpenSearch</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/examples/demo_transformer_model_train_save_upload_to_openSearch.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars and line breaks on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
    white-space: pre;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="Demo-Notebook-for-Sentence-Transformer-Model-Training,-Saving-and-Uploading-to-OpenSearch">
<h1>Demo Notebook for Sentence Transformer Model Training, Saving and Uploading to OpenSearch<a class="headerlink" href="#Demo-Notebook-for-Sentence-Transformer-Model-Training,-Saving-and-Uploading-to-OpenSearch" title="Permalink to this heading">¶</a></h1>
<p>This notebook provides a walkthrough guidance for users use their synthetic queries to fine tune and train a sentence transformer model. In this notebook, you use opensearch_py_ml to accomplish the following:</p>
<p>Step 0: Import packages and set up client</p>
<p>Step 1: Read synthetic queries and train/fine-tune model using a hugging face sentence transformer model</p>
<p>Step 2: (Optional) Save model</p>
<p>Step 3: Upload the model to OpenSearch cluster</p>
<section id="Step-0:-Import-packages-and-set-up-client">
<h2>Step 0: Import packages and set up client<a class="headerlink" href="#Step-0:-Import-packages-and-set-up-client" title="Permalink to this heading">¶</a></h2>
<p>Install required packages for opensearch_py_ml.sentence_transformer_model Install <code class="docutils literal notranslate"><span class="pre">opensearchpy</span></code> and <code class="docutils literal notranslate"><span class="pre">opensearch-py-ml</span></code> through pypi</p>
<p>Please refer <a class="reference external" href="https://pytorch.org/">https://pytorch.org/</a> to proper install torch based on your environment setting.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># pip install pandas matplotlib numpy torch accelerate sentence_transformers tqdm transformers opensearch-py opensearch-py-ml</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">opensearch_py_ml</span> <span class="k">as</span> <span class="nn">oml</span>
<span class="kn">from</span> <span class="nn">opensearchpy</span> <span class="kn">import</span> <span class="n">OpenSearch</span>
<span class="kn">from</span> <span class="nn">opensearch_py_ml.ml_models</span> <span class="kn">import</span> <span class="n">SentenceTransformerModel</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import mlcommon to later upload the model to OpenSearch Cluster</span>
<span class="kn">from</span> <span class="nn">opensearch_py_ml.ml_commons</span> <span class="kn">import</span> <span class="n">MLCommonClient</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">CLUSTER_URL</span> <span class="o">=</span> <span class="s1">&#39;https://localhost:9200&#39;</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_os_client</span><span class="p">(</span><span class="n">cluster_url</span> <span class="o">=</span> <span class="n">CLUSTER_URL</span><span class="p">,</span>
                  <span class="n">username</span><span class="o">=</span><span class="s1">&#39;admin&#39;</span><span class="p">,</span>
                  <span class="n">password</span><span class="o">=</span><span class="s1">&#39;admin&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Get OpenSearch client</span>
<span class="sd">    :param cluster_url: cluster URL like https://ml-te-netwo-1s12ba42br23v-ff1736fa7db98ff2.elb.us-west-2.amazonaws.com:443</span>
<span class="sd">    :return: OpenSearch client</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">client</span> <span class="o">=</span> <span class="n">OpenSearch</span><span class="p">(</span>
        <span class="n">hosts</span><span class="o">=</span><span class="p">[</span><span class="n">cluster_url</span><span class="p">],</span>
        <span class="n">http_auth</span><span class="o">=</span><span class="p">(</span><span class="n">username</span><span class="p">,</span> <span class="n">password</span><span class="p">),</span>
        <span class="n">verify_certs</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">client</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">client</span> <span class="o">=</span> <span class="n">get_os_client</span><span class="p">()</span>
</pre></div>
</div>
</div>
</section>
<section id="Step-1:-Read-synthetic-queries-and-train/fine-tune-model-using-a-hugging-face-sentence-transformer-model">
<h2>Step 1: Read synthetic queries and train/fine-tune model using a hugging face sentence transformer model<a class="headerlink" href="#Step-1:-Read-synthetic-queries-and-train/fine-tune-model-using-a-hugging-face-sentence-transformer-model" title="Permalink to this heading">¶</a></h2>
<p>With a synthetic queries zip file, users can fine tune a sentence transformer model.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">SentenceTransformerModel</span></code> class will inititate an object for training, exporting and configuring the model. Plese visit the <a class="reference external" href="https://opensearch-project.github.io/opensearch-py-ml/reference/api/sentence_transformer.html#opensearch_py_ml.sentence_transformer_model.SentenceTransformerModel">SentenceTransformerModel</a> for API Reference .</p>
<p>The <code class="docutils literal notranslate"><span class="pre">train</span></code> function will import synthestic queries, load sentence transformer example and train the model using a hugging face sentence transformer model. Plese visit the <a class="reference external" href="https://opensearch-project.github.io/opensearch-py-ml/reference/api/sentence_transformer.html#opensearch_py_ml.sentence_transformer_model.SentenceTransformerModel.train">SentenceTransformerModel.train</a> for API Reference .</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># clean up cache before training to free up spaces</span>
<span class="kn">import</span> <span class="nn">gc</span><span class="o">,</span> <span class="nn">torch</span>

<span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>

<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># initiate SentenceTransformerModel object and run train function</span>
<span class="c1"># num_processes should be less than the number of gpus on the users&#39; machine, if None, it will auto apply</span>
<span class="c1"># all the available gpus on the machine</span>
<span class="n">custom_model</span> <span class="o">=</span> <span class="n">SentenceTransformerModel</span><span class="p">(</span><span class="n">folder_path</span><span class="o">=</span><span class="s2">&quot;/Volumes/workplace/upload_content/model_files/&quot;</span><span class="p">,</span> <span class="n">overwrite</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">training</span> <span class="o">=</span> <span class="n">custom_model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">read_path</span> <span class="o">=</span> <span class="s1">&#39;/Volumes/workplace/upload_content/synthetic_queries.zip&#39;</span><span class="p">,</span>
                        <span class="n">output_model_name</span> <span class="o">=</span> <span class="s1">&#39;test2_model.pt&#39;</span><span class="p">,</span>
                        <span class="n">zip_file_name</span><span class="o">=</span> <span class="s1">&#39;test2_model.zip&#39;</span><span class="p">,</span>
                        <span class="n">overwrite</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                        <span class="n">use_accelerate</span>  <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                        <span class="n">num_machines</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                        <span class="n">num_processes</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                        <span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                        <span class="n">verbose</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
reading synthetic query file: /Volumes/workplace/upload_content/model_files/synthetic_queries/synthetic_queries_batch_3.p

reading synthetic query file: /Volumes/workplace/upload_content/model_files/synthetic_queries/synthetic_queries_batch_0.p

reading synthetic query file: /Volumes/workplace/upload_content/model_files/synthetic_queries/synthetic_queries_batch_1.p

reading synthetic query file: /Volumes/workplace/upload_content/model_files/synthetic_queries/synthetic_queries_batch_2.p

Loading training examples...

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|██████████| 243/243 [00:00&lt;00:00, 197064.17it/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[{&#39;compute_environment&#39;: &#39;LOCAL_MACHINE&#39;, &#39;deepspeed_config&#39;: {&#39;gradient_accumulation_steps&#39;: 1, &#39;offload_optimizer_device&#39;: &#39;none&#39;, &#39;offload_param_device&#39;: &#39;none&#39;, &#39;zero3_init_flag&#39;: False, &#39;zero_stage&#39;: 2}, &#39;distributed_type&#39;: &#39;DEEPSPEED&#39;, &#39;downcast_bf16&#39;: &#39;no&#39;, &#39;fsdp_config&#39;: {}, &#39;machine_rank&#39;: 0, &#39;main_process_ip&#39;: None, &#39;main_process_port&#39;: None, &#39;main_training_function&#39;: &#39;main&#39;, &#39;mixed_precision&#39;: &#39;no&#39;, &#39;num_machines&#39;: 1, &#39;num_processes&#39;: 1, &#39;use_cpu&#39;: False}]
Launching training on MPS.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Start training with accelerator...

The total number of steps training epoch are 8

Training epoch 0...

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100%|██████████| 8/8 [00:15&lt;00:00,  1.96s/it]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Total training time: 16.737305164337158

Model saved to path: /Volumes/workplace/upload_content/model_files/test2_model.pt

tokenizer_json_path:  /Volumes/workplace/upload_content/model_files/tokenizer.json
zip file is saved to /Volumes/workplace/upload_content/model_files/test2_model.zip

</pre></div></div>
</div>
</section>
<section id="Step-2:-(Optional)-Save-model">
<h2>Step 2: (Optional) Save model<a class="headerlink" href="#Step-2:-(Optional)-Save-model" title="Permalink to this heading">¶</a></h2>
<p>If following step 1, the model zip will be auto generated, and the print message will indicate the zip file path as shown above.</p>
<p>But if using other pretrained sentence transformer model from Hugging face, users can use <code class="docutils literal notranslate"><span class="pre">save_as_pt</span></code> function to save a pre-trained sentence transformer model for inferencing or benchmark with other models.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">save_as_pt</span></code> function will prepare the model in proper format(Torch Script) along with tokenizers configuration file to upload to OpenSearch. Plese visit the <a class="reference external" href="https://opensearch-project.github.io/opensearch-py-ml/reference/api/sentence_transformer.html#opensearch_py_ml.sentence_transformer_model.SentenceTransformerModel.save_as_pt">SentenceTransformerModel.save_as_pt</a> for API Reference .</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># default to download model id, &quot;sentence-transformers/msmarco-distilbert-base-tas-b&quot; from hugging face</span>
<span class="c1"># and output a model in a zip file containing model.pt file and tokenizers.json file.</span>
<span class="n">pre_trained_model</span> <span class="o">=</span> <span class="n">SentenceTransformerModel</span><span class="p">(</span><span class="n">folder_path</span> <span class="o">=</span> <span class="s1">&#39;/Volumes/workplace/upload_content/export_huggingface/&#39;</span><span class="p">,</span> <span class="n">overwrite</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">pre_trained_model</span><span class="o">.</span><span class="n">save_as_pt</span><span class="p">(</span><span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;today is sunny&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
model file is saved to  /Volumes/workplace/upload_content/export_huggingface/msmarco-distilbert-base-tas-b.pt
zip file is saved to  /Volumes/workplace/upload_content/export_huggingface/msmarco-distilbert-base-tas-b.zip

</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
SentenceTransformer(
  original_name=SentenceTransformer
  (0): Transformer(
    original_name=Transformer
    (auto_model): DistilBertModel(
      original_name=DistilBertModel
      (embeddings): Embeddings(
        original_name=Embeddings
        (word_embeddings): Embedding(original_name=Embedding)
        (position_embeddings): Embedding(original_name=Embedding)
        (LayerNorm): LayerNorm(original_name=LayerNorm)
        (dropout): Dropout(original_name=Dropout)
      )
      (transformer): Transformer(
        original_name=Transformer
        (layer): ModuleList(
          original_name=ModuleList
          (0): TransformerBlock(
            original_name=TransformerBlock
            (attention): MultiHeadSelfAttention(
              original_name=MultiHeadSelfAttention
              (dropout): Dropout(original_name=Dropout)
              (q_lin): Linear(original_name=Linear)
              (k_lin): Linear(original_name=Linear)
              (v_lin): Linear(original_name=Linear)
              (out_lin): Linear(original_name=Linear)
            )
            (sa_layer_norm): LayerNorm(original_name=LayerNorm)
            (ffn): FFN(
              original_name=FFN
              (dropout): Dropout(original_name=Dropout)
              (lin1): Linear(original_name=Linear)
              (lin2): Linear(original_name=Linear)
            )
            (output_layer_norm): LayerNorm(original_name=LayerNorm)
          )
          (1): TransformerBlock(
            original_name=TransformerBlock
            (attention): MultiHeadSelfAttention(
              original_name=MultiHeadSelfAttention
              (dropout): Dropout(original_name=Dropout)
              (q_lin): Linear(original_name=Linear)
              (k_lin): Linear(original_name=Linear)
              (v_lin): Linear(original_name=Linear)
              (out_lin): Linear(original_name=Linear)
            )
            (sa_layer_norm): LayerNorm(original_name=LayerNorm)
            (ffn): FFN(
              original_name=FFN
              (dropout): Dropout(original_name=Dropout)
              (lin1): Linear(original_name=Linear)
              (lin2): Linear(original_name=Linear)
            )
            (output_layer_norm): LayerNorm(original_name=LayerNorm)
          )
          (2): TransformerBlock(
            original_name=TransformerBlock
            (attention): MultiHeadSelfAttention(
              original_name=MultiHeadSelfAttention
              (dropout): Dropout(original_name=Dropout)
              (q_lin): Linear(original_name=Linear)
              (k_lin): Linear(original_name=Linear)
              (v_lin): Linear(original_name=Linear)
              (out_lin): Linear(original_name=Linear)
            )
            (sa_layer_norm): LayerNorm(original_name=LayerNorm)
            (ffn): FFN(
              original_name=FFN
              (dropout): Dropout(original_name=Dropout)
              (lin1): Linear(original_name=Linear)
              (lin2): Linear(original_name=Linear)
            )
            (output_layer_norm): LayerNorm(original_name=LayerNorm)
          )
          (3): TransformerBlock(
            original_name=TransformerBlock
            (attention): MultiHeadSelfAttention(
              original_name=MultiHeadSelfAttention
              (dropout): Dropout(original_name=Dropout)
              (q_lin): Linear(original_name=Linear)
              (k_lin): Linear(original_name=Linear)
              (v_lin): Linear(original_name=Linear)
              (out_lin): Linear(original_name=Linear)
            )
            (sa_layer_norm): LayerNorm(original_name=LayerNorm)
            (ffn): FFN(
              original_name=FFN
              (dropout): Dropout(original_name=Dropout)
              (lin1): Linear(original_name=Linear)
              (lin2): Linear(original_name=Linear)
            )
            (output_layer_norm): LayerNorm(original_name=LayerNorm)
          )
          (4): TransformerBlock(
            original_name=TransformerBlock
            (attention): MultiHeadSelfAttention(
              original_name=MultiHeadSelfAttention
              (dropout): Dropout(original_name=Dropout)
              (q_lin): Linear(original_name=Linear)
              (k_lin): Linear(original_name=Linear)
              (v_lin): Linear(original_name=Linear)
              (out_lin): Linear(original_name=Linear)
            )
            (sa_layer_norm): LayerNorm(original_name=LayerNorm)
            (ffn): FFN(
              original_name=FFN
              (dropout): Dropout(original_name=Dropout)
              (lin1): Linear(original_name=Linear)
              (lin2): Linear(original_name=Linear)
            )
            (output_layer_norm): LayerNorm(original_name=LayerNorm)
          )
          (5): TransformerBlock(
            original_name=TransformerBlock
            (attention): MultiHeadSelfAttention(
              original_name=MultiHeadSelfAttention
              (dropout): Dropout(original_name=Dropout)
              (q_lin): Linear(original_name=Linear)
              (k_lin): Linear(original_name=Linear)
              (v_lin): Linear(original_name=Linear)
              (out_lin): Linear(original_name=Linear)
            )
            (sa_layer_norm): LayerNorm(original_name=LayerNorm)
            (ffn): FFN(
              original_name=FFN
              (dropout): Dropout(original_name=Dropout)
              (lin1): Linear(original_name=Linear)
              (lin2): Linear(original_name=Linear)
            )
            (output_layer_norm): LayerNorm(original_name=LayerNorm)
          )
        )
      )
    )
  )
  (1): Pooling(original_name=Pooling)
)
</pre></div></div>
</div>
</section>
<section id="Step-3:-Upload-the-model-to-OpenSearch-cluster">
<h2>Step 3: Upload the model to OpenSearch cluster<a class="headerlink" href="#Step-3:-Upload-the-model-to-OpenSearch-cluster" title="Permalink to this heading">¶</a></h2>
<p>After generated a model zip file, the users will need to describe model configuration in a ml-commons_model_config.json file. The <code class="docutils literal notranslate"><span class="pre">make_model_config_json</span></code> function in sentencetransformermodel class will parse the config file from hugging-face config.son file. If users would like to use a different config than the pre-trained sentence transformer, <code class="docutils literal notranslate"><span class="pre">make_model_config_json</span></code> function provide arguuments to change the configuration content and generated a ml-commons_model_config.json file. Plese
visit the <a class="reference external" href="https://opensearch-project.github.io/opensearch-py-ml/reference/api/sentence_transformer.html#opensearch_py_ml.sentence_transformer_model.SentenceTransformerModel.make_model_config_json">SentenceTransformerModel.make_model_config_json</a> for API Reference .</p>
<p>In general, the ml common client supports uploading sentence transformer models. With a zip file contains model in Torch Script format, and a configuration file for tokenizers in json format, the <code class="docutils literal notranslate"><span class="pre">upload_model</span></code> function connects to opensearch through ml client and upload the model. Plese visit the <a class="reference external" href="https://opensearch-project.github.io/opensearch-py-ml/reference/api/ml_commons_upload_api.html#opensearch_py_ml.ml_commons_integration.MLCommonClient.upload_model">MLCommonClient.upload_model</a>
for API Reference.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#users will need to prepare a ml-commons_model_config.json file to config the model, including model name ..</span>
<span class="c1">#this is a helpful function in py-ml.sentence_transformer_model to generate ml-commons_model_config.json file</span>
<span class="n">custom_model</span><span class="o">.</span><span class="n">make_model_config_json</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
ml-commons_model_config.json file is saved at :  /Volumes/workplace/upload_content/model_files/ml-commons_model_config.json
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#connect to ml_common client with OpenSearch client</span>
<span class="kn">import</span> <span class="nn">opensearch_py_ml</span> <span class="k">as</span> <span class="nn">oml</span>
<span class="kn">from</span> <span class="nn">opensearch_py_ml.ml_commons</span> <span class="kn">import</span> <span class="n">MLCommonClient</span>
<span class="n">ml_client</span> <span class="o">=</span> <span class="n">MLCommonClient</span><span class="p">(</span><span class="n">client</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># upload model to OpenSearch cluster, using model zip file path and ml-commons_model_config.json file generated above</span>

<span class="n">model_path</span> <span class="o">=</span> <span class="s1">&#39;/Volumes/workplace/upload_content/model_files/test2_model.zip&#39;</span>
<span class="n">model_config_path</span> <span class="o">=</span> <span class="s1">&#39;/Volumes/workplace/upload_content/model_files/ml-commons_model_config.json&#39;</span>
<span class="n">ml_client</span><span class="o">.</span><span class="n">upload_model</span><span class="p">(</span> <span class="n">model_path</span><span class="p">,</span> <span class="n">model_config_path</span><span class="p">,</span> <span class="n">isVerbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Total number of chunks 27
Sha1 value of the model file:  1a198957ec8a759e83f1e862ad46bb120c6c1b5a031e75c415c1a893c87a3da7
Model meta data was created successfully. Model Id:  cz2RloUB6UQeRtfO8Jph
uploading chunk 1 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 2 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 3 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 4 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 5 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 6 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 7 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 8 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 9 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 10 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 11 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 12 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 13 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 14 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 15 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 16 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 17 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 18 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 19 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 20 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 21 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 22 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 23 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 24 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 25 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 26 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
uploading chunk 27 of 27
{&#39;status&#39;: &#39;Uploaded&#39;}
Model uploaded successfully
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&#39;cz2RloUB6UQeRtfO8Jph&#39;
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Now we can load the uploaded model into memory by using the model id.</span>


<span class="n">load_model_output</span> <span class="o">=</span> <span class="n">ml_client</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;cz2RloUB6UQeRtfO8Jph&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">load_model_output</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;task_id&#39;: &#39;dD2WloUB6UQeRtfOVJqe&#39;, &#39;status&#39;: &#39;CREATED&#39;}
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># When we call load_model to load a model a task will be initiated.</span>
<span class="c1"># We can see the task status with invoking `get_task_info` method using the task id</span>

<span class="n">task_info</span> <span class="o">=</span> <span class="n">ml_client</span><span class="o">.</span><span class="n">get_task_info</span><span class="p">(</span><span class="s2">&quot;dD2WloUB6UQeRtfOVJqe&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">task_info</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;model_id&#39;: &#39;cz2RloUB6UQeRtfO8Jph&#39;, &#39;task_type&#39;: &#39;LOAD_MODEL&#39;, &#39;function_name&#39;: &#39;TEXT_EMBEDDING&#39;, &#39;state&#39;: &#39;COMPLETED&#39;, &#39;worker_node&#39;: &#39;j6DmtPSRSHuHiqwxr6BnGw&#39;, &#39;create_time&#39;: 1673268712503, &#39;last_update_time&#39;: 1673268781057, &#39;is_async&#39;: True}
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We can also see model information with invoking `get_model_info` method using model id:</span>

<span class="n">model_info</span> <span class="o">=</span> <span class="n">ml_client</span><span class="o">.</span><span class="n">get_model_info</span><span class="p">(</span><span class="s2">&quot;cz2RloUB6UQeRtfO8Jph&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">model_info</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;name&#39;: &#39;sentence-transformers/msmarco-distilbert-base-tas-b&#39;, &#39;algorithm&#39;: &#39;TEXT_EMBEDDING&#39;, &#39;model_version&#39;: &#39;1&#39;, &#39;model_format&#39;: &#39;TORCH_SCRIPT&#39;, &#39;model_state&#39;: &#39;LOADED&#39;, &#39;model_content_hash_value&#39;: &#39;1a198957ec8a759e83f1e862ad46bb120c6c1b5a031e75c415c1a893c87a3da7&#39;, &#39;model_config&#39;: {&#39;model_type&#39;: &#39;distilbert&#39;, &#39;embedding_dimension&#39;: 768, &#39;framework_type&#39;: &#39;SENTENCE_TRANSFORMERS&#39;, &#39;all_config&#39;: &#39;{&#34;_name_or_path&#34;: &#34;/Users/dhrubo/.cache/torch/sentence_transformers/sentence-transformers_msmarco-distilbert-base-tas-b/&#34;, &#34;activation&#34;: &#34;gelu&#34;, &#34;architectures&#34;: [&#34;DistilBertModel&#34;], &#34;attention_dropout&#34;: 0.1, &#34;dim&#34;: 768, &#34;dropout&#34;: 0.1, &#34;hidden_dim&#34;: 3072, &#34;initializer_range&#34;: 0.02, &#34;max_position_embeddings&#34;: 512, &#34;model_type&#34;: &#34;distilbert&#34;, &#34;n_heads&#34;: 12, &#34;n_layers&#34;: 6, &#34;pad_token_id&#34;: 0, &#34;qa_dropout&#34;: 0.1, &#34;seq_classif_dropout&#34;: 0.2, &#34;sinusoidal_pos_embds&#34;: false, &#34;tie_weights_&#34;: true, &#34;torch_dtype&#34;: &#34;float32&#34;, &#34;transformers_version&#34;: &#34;4.16.2&#34;, &#34;vocab_size&#34;: 30522}&#39;}, &#39;created_time&#39;: 1673268424799, &#39;last_loaded_time&#39;: 1673268781057, &#39;total_chunks&#39;: 27}
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Now using this model we can generate sentence embedding.</span>

<span class="n">input_sentences</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Test sentence1&quot;</span><span class="p">,</span> <span class="s2">&quot;Test sentence2&quot;</span><span class="p">]</span>

<span class="n">embedding_output</span> <span class="o">=</span> <span class="n">ml_client</span><span class="o">.</span><span class="n">generate_embedding</span><span class="p">(</span><span class="s2">&quot;cz2RloUB6UQeRtfO8Jph&quot;</span><span class="p">,</span> <span class="n">input_sentences</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">embedding_output</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;inference_results&#39;: [{&#39;output&#39;: [{&#39;name&#39;: &#39;sentence_embedding&#39;, &#39;data_type&#39;: &#39;FLOAT32&#39;, &#39;shape&#39;: [768], &#39;data&#39;: [0.21162823, -0.31966814, -0.09601192, 0.14223084, 0.2264302, 0.19668405, 0.5970008, -0.19368923, -0.19195588, 0.3238238, -0.11029507, 0.20113745, -0.31363994, 0.218243, 0.42289385, 0.27342117, 0.409293, -0.36741465, -0.16032813, -0.13022901, 0.30196202, 0.46416682, -0.25054777, 0.14115417, 0.17647037, 0.04499317, 0.020941753, 0.21221676, -0.67876154, 0.17754197, -0.13002695, 0.15142015, 0.19277212, -0.08254553, 0.07795113, 0.49458084, -0.35918534, 0.10529865, 0.18471923, -0.15236725, -0.4106201, -0.4043108, -0.2681529, 0.09409851, -0.40124586, 0.15329781, -0.46914512, -0.16094545, -0.61767846, 0.43674526, -0.121316366, 0.93069077, 0.07570939, -0.087039694, -0.55987626, -0.048423957, -0.09163006, -0.4443902, 0.22732261, -0.1771088, 0.2349906, 0.36873037, -0.010825862, -0.29243731, 0.25782382, 0.13242388, 0.62139493, 0.76742977, -0.80710083, -0.40227658, 0.4170124, 0.5734022, -0.76480687, 0.42846662, 0.5296329, -0.33265075, 0.1765807, 0.18491475, -0.3693527, -0.02668656, -0.70957595, -0.0056749615, 0.23739026, 0.0043689585, 0.4024994, -0.07994666, -0.08355627, -0.033118393, -0.7084783, 0.24826792, -0.07947725, 0.013071969, -0.3634036, 0.22639994, 0.29759765, -0.10179385, -0.164081, -0.4602998, -0.32577047, -0.07180472, 0.46947452, -0.42037344, 0.6442718, 0.18102962, -0.1629775, 0.3712176, -0.20286368, -0.13776815, -0.41419736, 0.20932867, 0.48062932, 0.1341199, 0.056509573, -0.09015563, -0.2514935, -0.024856618, -0.23009543, 0.26418445, 0.0044808174, 0.43757653, -0.31142533, -0.2040665, 0.060129765, -0.21133329, 0.11189942, 0.0552195, 0.08785218, -0.061128955, -0.16669546, 0.016943967, 0.076269396, -0.16852456, 0.29971918, -0.09748537, -0.35528544, 0.15662184, -0.3387848, -0.35609752, -0.4636802, 0.13611437, 0.19580486, 0.03122427, 0.3302332, -0.18153088, 0.11799748, 0.00809692, -0.37070045, 0.54794836, 0.12838587, -0.13171469, -0.054314405, 0.43447274, -0.026003273, -0.45592138, -0.14061867, 0.3747074, -0.092506364, 0.09901216, -0.21235329, 0.2994793, -0.10771875, 0.12996857, 0.045164045, -0.017045906, 0.38847983, 0.42441574, 0.0828272, 0.5281231, -0.29139075, 0.32312015, -0.10109405, -0.5268522, 0.20092085, -0.14923322, -1.0225585, 0.69199747, 0.20742841, 0.03440954, 0.113565266, 0.052589815, -0.5174477, -0.12703414, -0.11529057, -0.085875146, 0.256431, 0.05405705, -0.10417899, -0.09519811, -0.041657533, 0.15803736, 0.016221369, -0.28770772, -0.06142842, -0.46510077, 0.62282664, -0.26295337, 0.0883226, 0.040936228, -0.17434779, 0.15474612, 0.12953274, 0.63483155, 0.29514912, -0.07170608, -0.31738552, 0.28032768, -0.1366847, -0.66946125, -0.34522328, 0.16254042, -0.7095064, 0.7157889, -0.02852299, -0.024774952, 0.021409577, -0.25500932, 0.3279837, 0.12911634, 0.23228373, -0.38109297, -0.033859648, -0.5538052, -0.15374672, 0.04447762, -0.3967278, 0.2538794, 0.280788, -0.059735473, -0.048173178, -0.5828414, -0.26733422, -0.22255164, 0.14646937, 0.31856522, -0.59677815, 0.20326133, -0.37663168, 0.0489204, -0.32451028, -0.41194364, -0.10399351, 0.32822764, -0.5551098, 0.645898, 0.08052145, 0.18267593, 0.513346, 0.11509277, -0.2529496, 0.037516523, -0.49482495, -0.20005895, -0.2267486, -0.2571585, -0.18357234, -0.07537524, -0.14439407, -0.03918905, -0.25468078, -0.14853285, 0.17895688, -0.15340166, -0.0006870864, -0.38412443, 0.077889144, -0.18963899, 0.08075544, -0.3017946, 0.30125678, 0.39804623, 0.2983063, -0.78084844, 0.26913378, -0.05632034, -0.0186966, -0.30374002, 0.5467043, 0.64381737, 0.30681255, -0.24589929, 0.2591313, -0.2117171, -0.08169094, 0.70956314, 0.6758064, 0.14889722, -0.29269305, 0.15414004, 0.074159145, -0.22216804, -0.16018021, 0.30309618, -0.0646563, -0.11705708, 0.36116198, -0.04228526, 0.40293965, -0.04123221, 0.44570354, 0.26593485, 0.15869902, 0.23216683, -0.4716716, 0.25382194, 0.08620844, 0.13832144, -0.13484477, -0.17317393, -7.8092504, 0.1278444, -0.17764558, -0.48143578, 0.49987713, -0.1818234, 0.11950158, 0.26877996, -0.67126393, -0.16035208, -0.7939753, 0.053709295, -0.14624003, 0.43974036, -0.009833282, -0.07327793, -0.49915624, -0.3063521, 0.2431481, 0.36224812, -0.35195655, 0.1620828, 0.34605694, -0.38992542, 0.18157221, 0.13366893, -0.49946964, 0.36481354, 0.19276415, -0.38090983, 0.57411975, -0.29663932, -0.5882188, -0.45947534, 0.1632109, -0.24160355, 0.14807422, -0.557621, 0.16025205, 0.29371566, -0.1337686, -0.2039315, 0.3015024, -0.18402787, -0.012761971, -0.1296718, -0.049202237, -0.03801413, 0.16470863, -0.11094821, -0.24144769, 0.8013586, 0.048721105, 0.07508891, -0.06467307, -0.15092781, 0.05516348, 0.020359186, -0.19386622, -0.37484106, -0.007014911, -0.29485214, -0.5280309, -0.43655148, 0.3361834, -0.9618877, -0.107431315, 0.11638585, 0.10046998, -0.33101025, -0.28798953, -0.18429267, -0.072578125, -1.0642596, -0.34083685, -0.28725344, 0.22275974, 0.14586803, 0.17118537, 0.18665029, -0.13921522, -0.10770547, -0.22291973, 0.19768564, 0.7066269, -0.29346856, -0.6375858, 0.28507942, -0.18580055, 0.14483352, 0.17718026, -0.18575518, 0.25274602, 0.40370816, -0.09740377, 0.31139123, 0.030053804, 0.20620456, 0.3153687, 0.03387117, -0.21482715, -0.39004755, 0.4688457, -0.38551298, -0.32554415, -0.09129284, -0.66529197, 0.22466621, 0.15437713, -0.2668594, -0.0036173142, -0.37549454, 0.30959138, 0.35961136, 0.27376994, -0.26943803, -0.24976017, 0.3460015, 0.7917013, 0.14044395, 0.20231025, -0.13179804, 0.039787266, -0.3296092, -0.1446193, -0.26299185, 0.4214473, 0.24691997, -0.25183415, -0.25437358, -0.48761007, 0.40883407, -0.5249168, 0.36173522, 0.42760712, -0.00021462241, -0.035019815, 0.050347213, 0.15263145, 0.3602537, 0.45618823, -0.30356392, 0.35745838, -0.3530839, 0.55963993, 0.25338936, 0.1818705, 0.27328596, -0.46434155, 0.06732647, 0.5381099, -0.34020332, 0.4054589, -0.23767325, -0.012719456, 0.06149467, -0.2685817, -0.30081257, -0.15681121, -0.21109146, -0.004519396, -0.034407802, -0.33104646, -0.24160488, -0.12077345, -0.09602944, -0.016811822, 0.63462543, 0.39521116, -0.064897895, -0.26481062, -0.020297375, 0.39476416, 0.61907417, 0.061261974, -0.11777243, 0.0063456697, -0.17077562, -0.012300495, 0.33865985, -0.46774256, -0.0669485, 0.09293734, -0.42635086, 0.57209986, 0.37725756, 0.7142184, 0.414121, 0.41829646, -0.2993509, -0.20253846, -0.15024106, 0.2566193, -0.028740808, -0.13615395, 0.07941768, 0.09479314, 0.021004109, -0.14435732, 0.582959, 0.12205118, -0.17547779, 0.4087336, -0.4557049, 0.63666785, -0.55875593, -0.3776887, 0.265242, 0.15676758, -0.2500386, 0.5883611, -0.5793501, -0.22867163, -0.14151862, -0.2618997, -0.55619895, -0.06706593, 0.23349729, -0.065744095, 0.14299616, -0.13536699, -0.17322941, 0.17596512, -0.34682643, -0.06477921, -0.32614532, -0.08355114, -0.34048167, 0.23272824, 0.5626833, -0.278456, 0.88953847, 0.15296176, 0.07279319, -0.3483889, -1.1452987, -0.37687144, -0.2345875, 0.0976802, 0.12807329, 0.1568633, -0.11549239, -0.06079996, -0.65922517, -0.02412083, 0.13499467, 0.4001376, -0.17325939, 0.2525725, 0.34433562, -0.05313701, -0.2475576, -0.49787313, 0.1995938, 0.07704235, 0.04207842, 0.19055721, -0.17212008, -0.32634163, 0.13496359, -0.03262729, -0.16189851, -0.057638187, -0.2877966, 0.22111839, 0.19537602, -0.27287355, 0.2762191, 0.4144123, 0.12330452, 0.1927393, -0.4721366, 0.112646736, 0.3885382, -0.10038415, 0.12175709, -0.41154933, 0.26112935, -0.07171466, 0.34610167, 0.15219241, 0.34582037, 0.47010577, 0.18750055, 0.018536352, -0.2672875, -0.19891565, 0.3866477, -0.15565729, -0.04006602, -0.23471642, 0.5256448, -0.33623832, -0.27359846, -0.30746484, 0.15818994, 0.043791052, 0.49608952, -0.37768766, -0.22958186, -0.5771064, 0.24892512, 0.46514216, -0.13610913, -0.31939137, -0.07657916, 0.53857064, -0.12640603, 0.2764302, -0.3524235, 0.36902842, 0.3195193, 0.45269394, -0.19159372, -0.4607417, -0.2261103, -0.15586714, -0.5851576, -0.30031767, 0.40051654, 0.18744496, -0.5444768, 0.518638, -0.11415654, -0.1899573, 0.32040682, 0.03302601, 0.13882895, 0.19468601, -0.06137322, 0.109930076, 0.15617767, 0.1614089, 0.3011247, -0.73561627, -0.15939829, -0.061141443, 0.055609167, 0.38660255, -0.030116485, 0.56405157, 0.14526813, -0.49251762, -0.5486328, -0.02956309, -0.2992378, -0.18951432, 0.29344782, -0.00037287743, 0.65368795, -0.31139603, 0.5058743, 0.3871841, 0.23362783, -0.13340858, -0.108210996, 0.20365164, 0.50980264, -0.6194681, 0.36360556, -0.03113519, 0.30452597, 0.639049, 0.26641548, -0.1654949, 0.11641952, 0.23528576, 0.25117663, 0.12116732, -0.044766057, 0.026696973, -0.16992539, -0.31838915, -0.027145477, -0.037670095, -0.23428202, -0.4357256, 0.08467599, -0.23691884, 0.16329534, -0.3074014, 0.5294487, 0.39169204, 0.009749279, -0.095272444, 0.65188926, 0.17775758, 0.006398245, 0.13602509, -0.3913643, -0.21700127, -0.2783131, 0.13091293, 0.7381406, -0.37396774, 0.23897068, 0.052415743, -0.0764465, 0.63306594, -0.04662975, 0.3790574, -0.60546833, 0.16866314, -0.18248954, 0.05022381, 1.0758909, 0.33540672, 0.24181831, -0.18853654, -0.36134264, 0.24753219, 0.2969436, -0.2860652, 0.03516555, -0.44456482, 0.049814716, 0.15241122, 0.37026638, -0.031931713, -0.33363092, -0.40836295, -0.20565873, -0.16321333, 0.41953382, -0.4813254, 0.4212471, -0.24964774, 0.05351434, -0.4540352, 0.2344464, -0.26814872, -0.32887152, 0.05116703, -0.30772495, -0.018659733, -0.3906824, 0.13845105, -0.060614496, -0.05308892, 0.12199924, -0.5885554, -0.06621002, 0.026791835, -0.20514253, 0.1541273, 0.10313303, -0.13980168, -0.17344765, 0.61261964, -0.521102, -0.15609746, -0.03930548, -0.27253577, -0.28965834, -0.14269385, 0.60747993, 0.46876985, 0.13417055, -0.1824232, -0.033269443]}]}, {&#39;output&#39;: [{&#39;name&#39;: &#39;sentence_embedding&#39;, &#39;data_type&#39;: &#39;FLOAT32&#39;, &#39;shape&#39;: [768], &#39;data&#39;: [0.0976517, -0.320867, 0.02855325, 0.17468324, 0.15656011, -0.038277928, 0.5754517, -0.2343755, -0.06607445, 0.25174758, -0.227193, 0.15590063, -0.28463334, 0.07616093, 0.58318543, -0.0072645815, 0.56809795, -0.43636394, -0.19478312, -0.25980836, 0.4302366, 0.45046657, -0.32618272, 0.1078021, 0.23805843, 0.12314865, 0.07989506, 0.17694469, -0.63336563, -0.027774276, -0.37197894, 0.14715266, -0.02956721, -0.026113654, 0.29478174, 0.57612306, -0.5613629, 0.069404244, 0.24716394, -0.21840388, -0.49224743, -0.17641324, -0.3368034, -0.057337098, -0.2919346, 0.16024835, -0.3780785, -0.057264578, -0.4035187, 0.3952106, -0.09763902, 0.92977655, 0.13789505, 0.024370084, -0.42205158, 0.08135688, -0.09463571, -0.32688138, 0.14553761, -0.40159416, 0.29050347, 0.37724155, -0.0054574106, -0.17300586, 0.06570772, 0.058566265, 0.53425187, 0.5850967, -0.81941754, -0.5514457, 0.28865403, 0.48372307, -0.9918569, 0.40006694, 0.30114678, -0.37877625, 0.0024522538, 0.21696343, -0.29749006, 0.110795416, -0.5277152, -0.020244524, 0.1178686, -0.07853561, 0.2824629, -0.00946273, 0.007716706, 0.02118358, -0.7648147, 0.07213303, -0.18499327, 0.016217725, -0.31600004, 0.35679263, 0.3924311, 0.043171827, -0.14647919, -0.36096916, -0.164576, -0.3007411, 0.24257584, -0.47805285, 0.631408, 0.22341435, -0.28887534, 0.15173577, -0.4275924, -0.055785708, -0.48630592, 0.24007426, 0.46996427, -0.053317137, 0.15503831, -0.12856553, -0.38900232, -0.04419699, -0.30829975, -0.0007491015, -0.17974278, 0.4900204, -0.22999898, -0.090369426, 0.1797884, -0.22998084, 0.13719988, -0.19320102, 0.11039105, -0.04958455, -0.30830544, 0.09452981, 0.049362425, -0.15916039, 0.38688537, 0.023361987, -0.20113462, -0.059965204, -0.37336302, -0.23470962, -0.6897105, 0.06790567, 0.20746894, 0.116179846, 0.3491181, -0.2638043, 0.28288713, 0.118571475, -0.35473055, 0.44784677, 0.30753353, -0.1325083, 0.09195009, 0.2591176, 0.07002315, -0.56851286, -0.2346988, 0.33983916, 0.085970424, 0.06357201, -0.22578245, 0.35639337, 0.036078457, -0.16765554, -0.059107006, -0.055707645, 0.30817813, 0.3540389, 0.02014744, 0.6219443, -0.2915104, 0.212823, -0.25342435, -0.6180313, 0.24722119, -0.079719596, -0.8690395, 0.58801174, 0.24375255, 0.085398965, 0.26400116, 0.06118353, -0.57287574, -0.099149525, -0.24879579, -0.118816175, 0.43171716, 0.05147933, -0.05158236, -0.272204, 0.033689544, 0.16697787, -0.04566793, -0.47248816, -0.059889488, -0.40747556, 0.4866978, -0.0446946, 0.17891857, 0.016956424, -0.16922909, 0.15983798, 0.04703397, 0.745211, 0.37140724, 0.00765166, -0.2175537, 0.11168152, 0.16302618, -0.6899172, -0.08700978, 0.17483227, -0.79566693, 0.74248844, -0.0066715674, -0.045400802, 0.054677773, -0.16783527, 0.42416283, -0.075153366, 0.17244165, -0.44089377, 0.0763161, -0.49910393, -0.053543657, 0.04091163, -0.3981778, 0.20702507, 0.06376265, -0.10431481, -0.037054744, -0.4635236, -0.44481602, -0.012914811, 0.3007159, 0.33417323, -0.54410976, 0.18420422, -0.26200917, 0.058715235, -0.2557978, -0.40350235, -0.07805473, 0.36042833, -0.41484004, 0.6469313, -0.052734528, 0.14528865, 0.45249206, -0.22273616, -0.21545707, -0.06955761, -0.33093917, -0.03844799, -0.009972254, -0.25949767, -0.21686162, -0.20028692, -0.14999004, -0.11506238, -0.25497496, -0.07403108, 0.15544418, -0.1402315, -0.10486371, -0.36487278, 0.10957087, -0.0323918, -0.021908205, -0.025873588, 0.26059383, 0.35818815, 0.19321252, -0.77050126, 0.2895783, -0.122294545, 0.018976033, -0.2271056, 0.54409903, 0.71235526, 0.25869584, -0.19772159, 0.016087975, -0.20858668, -0.09252286, 0.5946458, 0.60262066, 0.2819095, -0.2559569, 0.018464925, 0.13312839, -0.25286993, -0.08900075, 0.07221067, -0.06676735, 0.025039805, 0.42604548, -0.14921008, 0.4227737, -0.13582857, 0.5120123, 0.24470717, 0.04633012, 0.022734525, -0.5044117, 0.18774438, 0.09377883, 0.031099027, -0.106459714, -0.04902426, -7.8327794, 0.12437709, -0.18707989, -0.56771934, 0.62582046, 0.016868416, 0.29449895, 0.2803388, -0.72200924, -0.21060857, -0.9169944, 0.09276405, -0.08292397, 0.46488157, -0.078360625, 0.084486574, -0.24504398, -0.29402012, 0.26665106, 0.42462704, -0.21020702, 0.04185287, 0.25280902, -0.5308436, 0.024901584, 0.07757565, -0.6774656, 0.23412782, 0.21114056, -0.42416716, 0.45494628, -0.25682643, -0.3743435, -0.2927031, 0.14264636, -0.22730866, 0.11198494, -0.6342527, 0.39717937, 0.14804815, -0.19859886, -0.17400272, 0.4120723, 0.091495864, 0.034351997, -0.19181347, 0.07719729, 0.056193393, 0.08699708, -0.09988139, -0.30639052, 0.72960615, -0.02671382, 0.0451287, -0.11884615, -0.2926272, -0.089470506, 0.19295095, 0.10427616, -0.31301716, -0.0421933, -0.26418453, -0.53972197, -0.36296543, 0.25992766, -0.7282971, -0.15650938, -0.066362604, 0.16534077, -0.27933002, -0.37126917, -0.2529659, -0.059378896, -1.067559, -0.2580512, -0.06413946, 0.1514199, -0.059256684, 0.22851178, 0.052335884, -0.08683603, -0.24368699, -0.015992245, 0.34561768, 0.7320342, -0.42877823, -0.6016346, 0.3437164, -0.15654735, -0.010322357, 0.11829201, -0.24409996, 0.15585436, 0.27118218, -0.051629733, 0.35231778, 0.124152735, 0.061849933, 0.32209346, -0.07960814, -0.11463775, -0.4708408, 0.42978683, -0.44081897, -0.27597576, 0.14765444, -0.6961793, 0.37607035, -0.0610564, -0.29981112, -0.2980757, -0.37836426, 0.34655797, 0.24937674, 0.24881414, -0.36301547, -0.1723476, 0.1818383, 0.75704396, 0.24106024, 0.35638228, 0.072719954, 0.011406454, -0.36561087, -0.13965969, -0.28494865, 0.27246937, 0.1781205, -0.19793181, -0.1499348, -0.6575883, 0.235479, -0.5308097, 0.24966231, 0.36753374, -0.06960662, -0.022595005, 0.25427428, 0.34602052, 0.23010269, 0.6334664, -0.31640527, 0.60013235, -0.6423292, 0.5465511, 0.21942918, 0.29961494, 0.19825703, -0.4442087, 0.03518655, 0.49738586, -0.5536525, 0.4885954, -0.45225352, 0.023256034, 0.03905184, -0.3256025, 0.012873153, 0.11316428, -0.023236476, 0.046966095, -0.3033278, -0.42993227, 0.0043927506, -0.16324767, -0.007914204, 0.09353172, 0.46570617, 0.07123967, 0.058452267, -0.13772716, -0.10944601, 0.19945061, 0.8423675, 0.17102069, 0.0025709465, -0.017052436, -0.33006346, -0.022470886, 0.25033283, -0.45950097, -0.08440342, -0.11501935, -0.32684448, 0.60149384, 0.32131281, 0.79130405, 0.39812163, 0.4470684, -0.13835636, -0.13689135, -0.1894683, 0.20112902, -0.21667634, 0.0035761124, 0.17706798, -0.013909262, 0.054202456, -0.13179974, 0.5149375, 0.12206182, -0.071760155, 0.22239724, -0.60499984, 0.5527947, -0.489579, -0.3385238, 0.38709137, 0.3587606, -0.34067515, 0.6319081, -0.58719796, -0.041408986, -0.22490864, -0.34076884, -0.45636126, -0.13492595, 0.14075197, -0.2235896, 0.16677839, 0.014921746, -0.19323859, 0.025891589, -0.06987826, -0.091451846, -0.22682023, -0.09563604, -0.18486339, 0.3459472, 0.6207615, -0.05307387, 0.6361111, 0.11336618, 0.051503997, -0.3529823, -1.1427356, -0.39418885, 0.027451262, 0.2628689, 0.07070787, 0.40181178, -0.0628984, -0.06747911, -0.7338022, -0.051417165, 0.12434942, 0.44762713, -0.07760862, 0.26349962, 0.28053185, -0.005984671, -0.15039957, -0.554967, 0.08695569, 0.19919473, -0.1240649, 0.18983044, -0.149487, -0.40830135, -0.1250666, -0.036745798, 0.056929234, 0.016707353, -0.39488837, 0.12608808, 0.1895377, 0.0020687578, 0.16369244, 0.3883673, 0.12366511, 0.31772876, -0.41107112, 0.037521847, 0.31289414, -0.09970482, 0.06231721, -0.47209045, 0.3661919, 0.010286695, 0.3432243, 0.25480816, 0.38478026, 0.43864104, 0.056454316, 0.0043762685, -0.11615933, 0.022627085, 0.27127817, 0.039049447, 0.07832105, -0.40693453, 0.43900976, -0.2381036, -0.2799522, -0.2509349, 0.045433946, 0.028286602, 0.2615525, -0.40730953, -0.29319286, -0.5405191, 0.35679296, 0.42564833, -0.06923984, -0.19616899, 0.18142524, 0.7627177, -0.21873823, 0.06658555, -0.25315535, 0.4796108, 0.30012995, 0.35574234, -0.16228364, -0.3591989, -0.22066273, -0.16452976, -0.37798363, -0.23861675, 0.23872584, 0.30232736, -0.5556046, 0.51718676, -0.014387922, -0.18262093, 0.19305812, 0.15440002, 0.10474013, 0.22797409, -0.28005606, 0.096474126, 0.44272628, 0.32042187, 0.382921, -0.7259984, -0.0935844, 0.04630274, -0.028089944, 0.4557933, 0.1557463, 0.4413145, 0.16165803, -0.50576186, -0.39268222, -0.18382035, -0.1250331, -0.22752467, 0.15606506, -0.16243899, 0.5573804, -0.32799196, 0.4666818, 0.33233076, 0.27440536, -0.43740523, -0.068767466, 0.23477198, 0.3972387, -0.40985283, 0.282697, 0.12074196, 0.6004359, 0.70936257, 0.56290174, -0.108532265, -0.09051868, 0.18337873, 0.36070287, 0.111825734, -0.068524025, -0.07460696, -0.16514896, -0.13090108, -0.3470718, 0.08849225, -0.11750252, -0.4489691, 0.036498684, -0.24956751, 0.1849439, -0.28925782, 0.5394635, 0.4246067, 0.16941664, -0.09563263, 0.5292929, 0.15365495, 0.113757335, -0.030328115, -0.29178077, -0.003075069, -0.2762425, -0.28271914, 0.535744, -0.41785645, 0.2003931, 0.09418374, -0.2677725, 0.75448, 0.09811196, 0.46613532, -0.6916233, 0.013174239, -0.25394022, 0.042103905, 0.89746547, 0.37838835, 0.4426656, -0.36638683, -0.3053904, 0.09552713, 0.20300367, -0.39109993, 0.070596606, -0.32513008, 0.12682436, 0.12629, 0.37072772, 0.16468173, -0.1254265, -0.51331985, -0.21557279, -0.07638916, 0.49830526, -0.5950732, 0.4968121, -0.3110786, -0.11903289, -0.4143922, 0.15931928, 0.13579014, -0.39440694, 0.058438737, -0.29066187, -0.066448495, -0.5356716, -0.05591101, 0.047642566, -0.028238133, -0.07790613, -0.4438986, -0.07489307, 0.23017335, -0.02107644, -0.1592645, 0.16983365, 0.004289625, -0.33526042, 0.79059017, -0.38604042, -0.06759483, 0.15107623, -0.3984899, -0.23152249, 0.008065893, 0.57153296, 0.44597808, 0.10026479, 0.008029249, -0.17854127]}]}]}
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Now we can unload the model from opensearch nodes by invoking `unload_model`:</span>

<span class="n">unload_model_response</span> <span class="o">=</span> <span class="n">ml_client</span><span class="o">.</span><span class="n">unload_model</span><span class="p">(</span><span class="s2">&quot;cz2RloUB6UQeRtfO8Jph&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">unload_model_response</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
unload api output: {&#39;j6DmtPSRSHuHiqwxr6BnGw&#39;: {&#39;stats&#39;: {&#39;cz2RloUB6UQeRtfO8Jph&#39;: &#39;unloaded&#39;}}}
{&#39;j6DmtPSRSHuHiqwxr6BnGw&#39;: {&#39;stats&#39;: {&#39;cz2RloUB6UQeRtfO8Jph&#39;: &#39;unloaded&#39;}}}
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We can also delete the model:</span>

<span class="n">delete_model_response</span> <span class="o">=</span> <span class="n">ml_client</span><span class="o">.</span><span class="n">delete_model</span><span class="p">(</span><span class="s2">&quot;cz2RloUB6UQeRtfO8Jph&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">delete_model_response</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;_index&#39;: &#39;.plugins-ml-model&#39;, &#39;_id&#39;: &#39;cz2RloUB6UQeRtfO8Jph&#39;, &#39;_version&#39;: 6, &#39;result&#39;: &#39;deleted&#39;, &#39;_shards&#39;: {&#39;total&#39;: 2, &#39;successful&#39;: 1, &#39;failed&#39;: 0}, &#39;_seq_no&#39;: 32, &#39;_primary_term&#39;: 1}
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</section>
</section>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="online_retail_analysis.html" class="btn btn-neutral float-left" title="Online Retail analysis" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2023, Opensearch.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>